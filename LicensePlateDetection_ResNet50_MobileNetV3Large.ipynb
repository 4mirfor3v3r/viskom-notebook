{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Detector using MobilenetV3Large Rewsnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotation, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.coco = COCO(annotation)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Own coco file\n",
    "        coco = self.coco\n",
    "        # Image ID\n",
    "        img_id = self.ids[index]\n",
    "        # List: get annotation id from coco\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        # Dictionary: target coco_annotation file for an image\n",
    "        coco_annotation = coco.loadAnns(ann_ids)\n",
    "        # path for input image\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        # open the input image\n",
    "        img = Image.open(os.path.join(self.root, path))\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "        # number of objects in the image\n",
    "        num_objs = len(coco_annotation)\n",
    "\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            xmin = coco_annotation[i]['bbox'][0]\n",
    "            ymin = coco_annotation[i]['bbox'][1]\n",
    "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
    "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # Labels (In my case, I only one class: target class or background)\n",
    "        labels = torch.ones(num_objs, dtype=torch.int64)\n",
    "        # Tensorise img_id\n",
    "        img_id = torch.tensor(img_id)\n",
    "        # Size of bbox (Rectangular)\n",
    "        areas = []\n",
    "        for i in range(num_objs):\n",
    "            areas.append(coco_annotation[i]['area'])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        # Iscrowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        if num_objs == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "            areas = torch.zeros((0,), dtype=torch.float32)\n",
    "            iscrowd = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = img_id\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            if not isinstance(img, Image.Image):\n",
    "                img = Image.fromarray(img)\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# path to your own data and coco file\n",
    "import utils\n",
    "train_data_dir = 'data/train'\n",
    "train_coco = 'data/train/_annotations.coco.json'\n",
    "\n",
    "test_data_dir = 'data/test'\n",
    "test_coco = 'data/test/_annotations.coco.json'\n",
    "\n",
    "valid_data_dir = 'data/valid'\n",
    "valid_coco = 'data/valid/_annotations.coco.json'\n",
    "\n",
    "# create own Dataset\n",
    "train_ds = CustomDataset(root=train_data_dir,\n",
    "                          annotation=train_coco,\n",
    "                          transforms=get_transform(train=True)\n",
    "                          )\n",
    "\n",
    "test_ds = CustomDataset(root=test_data_dir,\n",
    "                          annotation=test_coco,\n",
    "                          transforms=get_transform(train=False)\n",
    "                          )\n",
    "\n",
    "valid_ds = CustomDataset(root=valid_data_dir,\n",
    "                          annotation=valid_coco,\n",
    "                          transforms=get_transform(train=False)\n",
    "                          )\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Batch size\n",
    "train_batch_size = 4\n",
    "test_batch_size = 4\n",
    "valid_batch_size = 4\n",
    "\n",
    "# own DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_ds,\n",
    "                                          batch_size=train_batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          collate_fn=utils.collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_ds,\n",
    "                                            batch_size=test_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            collate_fn=utils.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(valid_ds,\n",
    "                                            batch_size=valid_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "# load a pre-trained model for classification and return\n",
    "# only the features\n",
    "backbone = torchvision.models.mobilenet_v3_large(weights=\"DEFAULT\").features\n",
    "# ``FasterRCNN`` needs to know the number of\n",
    "# so we need to add it here\n",
    "backbone.out_channels = 960\n",
    "\n",
    "# let's make the RPN generate 5 x 3 anchors per spatial\n",
    "# location, with 5 different sizes and 3 different aspect\n",
    "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
    "# map could potentially have different sizes and\n",
    "# aspect ratios\n",
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=((32, 64, 128, 256, 512),),\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
    ")\n",
    "\n",
    "# let's define what are the feature maps that we will\n",
    "# use to perform the region of interest cropping, as well as\n",
    "# the size of the crop after rescaling.\n",
    "# if your backbone returns a Tensor, featmap_names is expected to\n",
    "# be [0]. More generally, the backbone should return an\n",
    "# ``OrderedDict[Tensor]``, and in ``featmap_names`` you can choose which\n",
    "# feature maps to use.\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "    featmap_names=['0'],\n",
    "    output_size=7,\n",
    "    sampling_ratio=2\n",
    ")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# put the pieces together inside a Faster-RCNN model\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=2,\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "def getIoU(bbox, gt):\n",
    "    x1, y1, w1, h1 = bbox\n",
    "    x2, y2, w2, h2 = gt\n",
    "    xA = max(x1, x2)\n",
    "    yA = max(y1, y2)\n",
    "    xB = min(x1+w1, x2+w2)\n",
    "    yB = min(y1+h1, y2+h2)\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = w1 * h1\n",
    "    boxBArea = w2 * h2\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "# mean average precision\n",
    "def get_mAP(pred_boxes, pred_labels, pred_scores, gt_boxes, gt_labels):\n",
    "    # get mAP\n",
    "    pred = [{'boxes': pred_boxes, 'labels': pred_labels, 'scores': pred_scores}]\n",
    "    gt = [{'boxes': gt_boxes, 'labels': gt_labels}]\n",
    "    map_metric = MeanAveragePrecision(iou_thresholds=[0.5], class_metrics=True)\n",
    "    map_metric.update(pred, gt)\n",
    "    mAP = map_metric.compute()\n",
    "    return mAP['map']\n",
    "\n",
    "\n",
    "def validate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    average_IoU = 0\n",
    "\n",
    "    mAP = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            pred = model(images)\n",
    "            pred_boxes = pred[0]['boxes'].cpu()\n",
    "            pred_labels = pred[0]['labels'].cpu()\n",
    "            pred_scores = pred[0]['scores'].cpu()\n",
    "            \n",
    "            gt_boxes = targets[0]['boxes'].cpu()\n",
    "            gt_labels = targets[0]['labels'].cpu()\n",
    "            # get mAP\n",
    "            if(len(pred_boxes) == 0):\n",
    "                continue\n",
    "            mAP += get_mAP(pred_boxes, pred_labels, pred_scores, gt_boxes, gt_labels)\n",
    "            pred_boxes = pred[0]['boxes'].cpu().numpy()\n",
    "            pred_labels = pred[0]['labels'].cpu().numpy()\n",
    "            pred_scores = pred[0]['scores'].cpu().numpy()\n",
    "\n",
    "            gt_boxes = targets[0]['boxes'].cpu().numpy()\n",
    "            gt_labels = targets[0]['labels'].cpu().numpy()\n",
    "\n",
    "            # get IoU\n",
    "            if(len(pred_boxes) == 0):\n",
    "                continue\n",
    "            iou = getIoU(pred_boxes[0], gt_boxes[0])\n",
    "            average_IoU += iou\n",
    "\n",
    "    average_IoU /= len(data_loader)\n",
    "    mAP /= len(data_loader)\n",
    "\n",
    "    return average_IoU, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\engine.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=scaler is not None):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/301]  eta: 0:09:21  lr: 0.000022  loss: 1.5516 (1.5516)  loss_classifier: 0.6835 (0.6835)  loss_box_reg: 0.0118 (0.0118)  loss_objectness: 0.7191 (0.7191)  loss_rpn_box_reg: 0.1372 (0.1372)  time: 1.8649  data: 0.1130  max mem: 4937\n",
      "Epoch: [0]  [ 10/301]  eta: 0:02:33  lr: 0.000188  loss: 1.4618 (1.4818)  loss_classifier: 0.6722 (0.6579)  loss_box_reg: 0.0125 (0.0134)  loss_objectness: 0.7116 (0.7124)  loss_rpn_box_reg: 0.0781 (0.0982)  time: 0.5277  data: 0.0375  max mem: 5816\n",
      "Epoch: [0]  [ 20/301]  eta: 0:06:52  lr: 0.000355  loss: 1.4248 (1.3909)  loss_classifier: 0.5721 (0.5542)  loss_box_reg: 0.0224 (0.0226)  loss_objectness: 0.7060 (0.7047)  loss_rpn_box_reg: 0.0820 (0.1094)  time: 1.4481  data: 0.0369  max mem: 7547\n",
      "Epoch: [0]  [ 30/301]  eta: 0:07:28  lr: 0.000521  loss: 1.1258 (1.2691)  loss_classifier: 0.3200 (0.4463)  loss_box_reg: 0.0395 (0.0331)  loss_objectness: 0.6770 (0.6863)  loss_rpn_box_reg: 0.0904 (0.1034)  time: 2.2734  data: 0.0354  max mem: 7547\n",
      "Epoch: [0]  [ 40/301]  eta: 0:06:38  lr: 0.000688  loss: 0.9414 (1.1839)  loss_classifier: 0.1731 (0.3781)  loss_box_reg: 0.0475 (0.0400)  loss_objectness: 0.6157 (0.6658)  loss_rpn_box_reg: 0.0788 (0.0999)  time: 1.5881  data: 0.0275  max mem: 7547\n",
      "Epoch: [0]  [ 50/301]  eta: 0:05:30  lr: 0.000854  loss: 0.9227 (1.1465)  loss_classifier: 0.2132 (0.3580)  loss_box_reg: 0.0799 (0.0559)  loss_objectness: 0.5608 (0.6377)  loss_rpn_box_reg: 0.0596 (0.0949)  time: 0.7978  data: 0.0309  max mem: 7547\n",
      "Epoch: [0]  [ 60/301]  eta: 0:05:16  lr: 0.001021  loss: 0.9563 (1.1098)  loss_classifier: 0.2733 (0.3434)  loss_box_reg: 0.1082 (0.0666)  loss_objectness: 0.4934 (0.6098)  loss_rpn_box_reg: 0.0555 (0.0898)  time: 0.8721  data: 0.0306  max mem: 7547\n",
      "Epoch: [0]  [ 70/301]  eta: 0:04:34  lr: 0.001187  loss: 0.8640 (1.0788)  loss_classifier: 0.2733 (0.3293)  loss_box_reg: 0.1391 (0.0821)  loss_objectness: 0.4316 (0.5812)  loss_rpn_box_reg: 0.0418 (0.0862)  time: 0.8598  data: 0.0320  max mem: 7547\n",
      "Epoch: [0]  [ 80/301]  eta: 0:04:04  lr: 0.001354  loss: 0.7746 (1.0417)  loss_classifier: 0.2006 (0.3147)  loss_box_reg: 0.1421 (0.0906)  loss_objectness: 0.3784 (0.5545)  loss_rpn_box_reg: 0.0418 (0.0819)  time: 0.4852  data: 0.0373  max mem: 7547\n",
      "Epoch: [0]  [ 90/301]  eta: 0:03:51  lr: 0.001520  loss: 0.6704 (1.0006)  loss_classifier: 0.1727 (0.2977)  loss_box_reg: 0.1302 (0.0956)  loss_objectness: 0.3377 (0.5277)  loss_rpn_box_reg: 0.0552 (0.0796)  time: 0.7631  data: 0.0454  max mem: 7547\n",
      "Epoch: [0]  [100/301]  eta: 0:03:36  lr: 0.001687  loss: 0.6601 (0.9711)  loss_classifier: 0.1636 (0.2848)  loss_box_reg: 0.1419 (0.1032)  loss_objectness: 0.3016 (0.5053)  loss_rpn_box_reg: 0.0522 (0.0779)  time: 0.9511  data: 0.0497  max mem: 7547\n",
      "Epoch: [0]  [110/301]  eta: 0:03:13  lr: 0.001853  loss: 0.6497 (0.9365)  loss_classifier: 0.1617 (0.2722)  loss_box_reg: 0.1661 (0.1077)  loss_objectness: 0.2812 (0.4815)  loss_rpn_box_reg: 0.0431 (0.0751)  time: 0.6334  data: 0.0439  max mem: 7547\n",
      "Epoch: [0]  [120/301]  eta: 0:02:52  lr: 0.002020  loss: 0.5787 (0.9087)  loss_classifier: 0.1487 (0.2628)  loss_box_reg: 0.1593 (0.1122)  loss_objectness: 0.2082 (0.4596)  loss_rpn_box_reg: 0.0431 (0.0743)  time: 0.3402  data: 0.0337  max mem: 7547\n",
      "Epoch: [0]  [130/301]  eta: 0:02:45  lr: 0.002186  loss: 0.5562 (0.8829)  loss_classifier: 0.1460 (0.2545)  loss_box_reg: 0.1638 (0.1165)  loss_objectness: 0.1941 (0.4392)  loss_rpn_box_reg: 0.0483 (0.0727)  time: 0.7326  data: 0.0278  max mem: 7547\n",
      "Epoch: [0]  [140/301]  eta: 0:02:29  lr: 0.002353  loss: 0.5139 (0.8587)  loss_classifier: 0.1401 (0.2472)  loss_box_reg: 0.1558 (0.1190)  loss_objectness: 0.1670 (0.4202)  loss_rpn_box_reg: 0.0447 (0.0722)  time: 0.7841  data: 0.0331  max mem: 7547\n",
      "Epoch: [0]  [150/301]  eta: 0:02:14  lr: 0.002519  loss: 0.4605 (0.8302)  loss_classifier: 0.1294 (0.2389)  loss_box_reg: 0.1375 (0.1202)  loss_objectness: 0.1431 (0.4011)  loss_rpn_box_reg: 0.0411 (0.0700)  time: 0.3787  data: 0.0310  max mem: 7547\n",
      "Epoch: [0]  [160/301]  eta: 0:02:00  lr: 0.002686  loss: 0.3783 (0.8013)  loss_classifier: 0.1022 (0.2304)  loss_box_reg: 0.1107 (0.1188)  loss_objectness: 0.1265 (0.3838)  loss_rpn_box_reg: 0.0288 (0.0683)  time: 0.3370  data: 0.0287  max mem: 7547\n",
      "Epoch: [0]  [170/301]  eta: 0:01:54  lr: 0.002852  loss: 0.3471 (0.7744)  loss_classifier: 0.0947 (0.2223)  loss_box_reg: 0.0949 (0.1171)  loss_objectness: 0.1182 (0.3682)  loss_rpn_box_reg: 0.0436 (0.0669)  time: 0.7304  data: 0.0443  max mem: 7547\n",
      "Epoch: [0]  [180/301]  eta: 0:01:44  lr: 0.003019  loss: 0.3247 (0.7508)  loss_classifier: 0.0792 (0.2139)  loss_box_reg: 0.0740 (0.1143)  loss_objectness: 0.1168 (0.3561)  loss_rpn_box_reg: 0.0453 (0.0665)  time: 0.9067  data: 0.0543  max mem: 7547\n",
      "Epoch: [0]  [190/301]  eta: 0:01:37  lr: 0.003185  loss: 0.2817 (0.7268)  loss_classifier: 0.0692 (0.2068)  loss_box_reg: 0.0706 (0.1123)  loss_objectness: 0.0992 (0.3426)  loss_rpn_box_reg: 0.0363 (0.0651)  time: 0.9420  data: 0.0410  max mem: 7547\n",
      "Epoch: [0]  [200/301]  eta: 0:01:27  lr: 0.003352  loss: 0.2825 (0.7083)  loss_classifier: 0.0778 (0.2007)  loss_box_reg: 0.0711 (0.1108)  loss_objectness: 0.0992 (0.3320)  loss_rpn_box_reg: 0.0363 (0.0649)  time: 0.9068  data: 0.0340  max mem: 7547\n",
      "Epoch: [0]  [210/301]  eta: 0:01:18  lr: 0.003518  loss: 0.3456 (0.6912)  loss_classifier: 0.0792 (0.1954)  loss_box_reg: 0.0756 (0.1101)  loss_objectness: 0.1015 (0.3213)  loss_rpn_box_reg: 0.0503 (0.0645)  time: 0.6427  data: 0.0442  max mem: 7547\n",
      "Epoch: [0]  [220/301]  eta: 0:01:11  lr: 0.003685  loss: 0.3134 (0.6748)  loss_classifier: 0.0757 (0.1902)  loss_box_reg: 0.0755 (0.1091)  loss_objectness: 0.0914 (0.3112)  loss_rpn_box_reg: 0.0377 (0.0642)  time: 1.0391  data: 0.0429  max mem: 7547\n",
      "Epoch: [0]  [230/301]  eta: 0:01:04  lr: 0.003851  loss: 0.3116 (0.6599)  loss_classifier: 0.0741 (0.1855)  loss_box_reg: 0.0724 (0.1082)  loss_objectness: 0.0894 (0.3019)  loss_rpn_box_reg: 0.0314 (0.0643)  time: 1.4931  data: 0.0397  max mem: 7547\n",
      "Epoch: [0]  [240/301]  eta: 0:00:54  lr: 0.004018  loss: 0.3116 (0.6458)  loss_classifier: 0.0700 (0.1806)  loss_box_reg: 0.0706 (0.1065)  loss_objectness: 0.0894 (0.2943)  loss_rpn_box_reg: 0.0402 (0.0645)  time: 0.9709  data: 0.0343  max mem: 7547\n",
      "Epoch: [0]  [250/301]  eta: 0:00:44  lr: 0.004184  loss: 0.3160 (0.6366)  loss_classifier: 0.0802 (0.1771)  loss_box_reg: 0.0762 (0.1063)  loss_objectness: 0.1011 (0.2876)  loss_rpn_box_reg: 0.0582 (0.0656)  time: 0.4479  data: 0.0290  max mem: 7547\n",
      "Epoch: [0]  [260/301]  eta: 0:00:35  lr: 0.004351  loss: 0.3160 (0.6244)  loss_classifier: 0.0812 (0.1734)  loss_box_reg: 0.0762 (0.1049)  loss_objectness: 0.0885 (0.2798)  loss_rpn_box_reg: 0.0520 (0.0662)  time: 0.4384  data: 0.0305  max mem: 7547\n",
      "Epoch: [0]  [270/301]  eta: 0:00:25  lr: 0.004517  loss: 0.2587 (0.6110)  loss_classifier: 0.0671 (0.1694)  loss_box_reg: 0.0602 (0.1031)  loss_objectness: 0.0874 (0.2726)  loss_rpn_box_reg: 0.0483 (0.0659)  time: 0.3621  data: 0.0277  max mem: 7547\n",
      "Epoch: [0]  [280/301]  eta: 0:00:17  lr: 0.004684  loss: 0.2219 (0.5971)  loss_classifier: 0.0618 (0.1653)  loss_box_reg: 0.0506 (0.1012)  loss_objectness: 0.0642 (0.2654)  loss_rpn_box_reg: 0.0465 (0.0652)  time: 0.3770  data: 0.0287  max mem: 7547\n",
      "Epoch: [0]  [290/301]  eta: 0:00:09  lr: 0.004850  loss: 0.1940 (0.5843)  loss_classifier: 0.0518 (0.1612)  loss_box_reg: 0.0498 (0.0992)  loss_objectness: 0.0631 (0.2588)  loss_rpn_box_reg: 0.0488 (0.0651)  time: 0.5914  data: 0.0350  max mem: 7547\n",
      "Epoch: [0]  [300/301]  eta: 0:00:00  lr: 0.005000  loss: 0.2425 (0.5736)  loss_classifier: 0.0443 (0.1575)  loss_box_reg: 0.0474 (0.0975)  loss_objectness: 0.0683 (0.2534)  loss_rpn_box_reg: 0.0610 (0.0652)  time: 1.0585  data: 0.0333  max mem: 7547\n",
      "Epoch: [0] Total time: 0:04:11 (0.8371 s / it)\n",
      "IoU: 0.6544909477233887, mAP: 0.8014277815818787\n",
      "Epoch: [1]  [  0/301]  eta: 0:02:07  lr: 0.005000  loss: 0.5047 (0.5047)  loss_classifier: 0.0486 (0.0486)  loss_box_reg: 0.0352 (0.0352)  loss_objectness: 0.2083 (0.2083)  loss_rpn_box_reg: 0.2127 (0.2127)  time: 0.4240  data: 0.0175  max mem: 7547\n",
      "Epoch: [1]  [ 10/301]  eta: 0:04:03  lr: 0.005000  loss: 0.2469 (0.2982)  loss_classifier: 0.0486 (0.0473)  loss_box_reg: 0.0460 (0.0474)  loss_objectness: 0.0805 (0.0964)  loss_rpn_box_reg: 0.0709 (0.1071)  time: 0.8358  data: 0.0164  max mem: 7547\n",
      "Epoch: [1]  [ 20/301]  eta: 0:04:40  lr: 0.005000  loss: 0.2613 (0.3011)  loss_classifier: 0.0468 (0.0491)  loss_box_reg: 0.0451 (0.0471)  loss_objectness: 0.0794 (0.0962)  loss_rpn_box_reg: 0.0709 (0.1087)  time: 1.0262  data: 0.0262  max mem: 7547\n",
      "Epoch: [1]  [ 30/301]  eta: 0:07:02  lr: 0.005000  loss: 0.2740 (0.2924)  loss_classifier: 0.0492 (0.0510)  loss_box_reg: 0.0503 (0.0524)  loss_objectness: 0.0794 (0.0916)  loss_rpn_box_reg: 0.0693 (0.0974)  time: 1.9566  data: 0.0340  max mem: 7547\n",
      "Epoch: [1]  [ 40/301]  eta: 0:06:00  lr: 0.005000  loss: 0.2342 (0.2779)  loss_classifier: 0.0505 (0.0502)  loss_box_reg: 0.0503 (0.0515)  loss_objectness: 0.0671 (0.0878)  loss_rpn_box_reg: 0.0605 (0.0885)  time: 1.7810  data: 0.0237  max mem: 7547\n",
      "Epoch: [1]  [ 50/301]  eta: 0:05:09  lr: 0.005000  loss: 0.2294 (0.2734)  loss_classifier: 0.0486 (0.0506)  loss_box_reg: 0.0480 (0.0512)  loss_objectness: 0.0671 (0.0884)  loss_rpn_box_reg: 0.0553 (0.0831)  time: 0.7293  data: 0.0171  max mem: 7547\n",
      "Epoch: [1]  [ 60/301]  eta: 0:04:33  lr: 0.005000  loss: 0.2208 (0.2650)  loss_classifier: 0.0511 (0.0512)  loss_box_reg: 0.0535 (0.0520)  loss_objectness: 0.0579 (0.0844)  loss_rpn_box_reg: 0.0528 (0.0774)  time: 0.6283  data: 0.0225  max mem: 7547\n",
      "Epoch: [1]  [ 70/301]  eta: 0:04:11  lr: 0.005000  loss: 0.1669 (0.2512)  loss_classifier: 0.0423 (0.0496)  loss_box_reg: 0.0380 (0.0494)  loss_objectness: 0.0534 (0.0802)  loss_rpn_box_reg: 0.0345 (0.0719)  time: 0.7236  data: 0.0206  max mem: 7547\n",
      "Epoch: [1]  [ 80/301]  eta: 0:03:56  lr: 0.005000  loss: 0.1686 (0.2455)  loss_classifier: 0.0396 (0.0484)  loss_box_reg: 0.0340 (0.0474)  loss_objectness: 0.0583 (0.0799)  loss_rpn_box_reg: 0.0449 (0.0698)  time: 0.8815  data: 0.0191  max mem: 7578\n",
      "Epoch: [1]  [ 90/301]  eta: 0:04:02  lr: 0.005000  loss: 0.1838 (0.2373)  loss_classifier: 0.0396 (0.0475)  loss_box_reg: 0.0333 (0.0461)  loss_objectness: 0.0583 (0.0773)  loss_rpn_box_reg: 0.0392 (0.0664)  time: 1.3522  data: 0.0231  max mem: 7578\n",
      "Epoch: [1]  [100/301]  eta: 0:03:35  lr: 0.005000  loss: 0.1648 (0.2302)  loss_classifier: 0.0413 (0.0471)  loss_box_reg: 0.0367 (0.0456)  loss_objectness: 0.0542 (0.0749)  loss_rpn_box_reg: 0.0316 (0.0626)  time: 1.0749  data: 0.0188  max mem: 7578\n",
      "Epoch: [1]  [110/301]  eta: 0:03:42  lr: 0.005000  loss: 0.1658 (0.2240)  loss_classifier: 0.0403 (0.0462)  loss_box_reg: 0.0370 (0.0445)  loss_objectness: 0.0507 (0.0727)  loss_rpn_box_reg: 0.0311 (0.0606)  time: 1.2328  data: 0.0285  max mem: 7643\n",
      "Epoch: [1]  [120/301]  eta: 0:04:00  lr: 0.005000  loss: 0.1696 (0.2230)  loss_classifier: 0.0389 (0.0465)  loss_box_reg: 0.0374 (0.0451)  loss_objectness: 0.0490 (0.0724)  loss_rpn_box_reg: 0.0311 (0.0590)  time: 2.6320  data: 0.0383  max mem: 7643\n",
      "Epoch: [1]  [130/301]  eta: 0:03:36  lr: 0.005000  loss: 0.1745 (0.2175)  loss_classifier: 0.0419 (0.0460)  loss_box_reg: 0.0393 (0.0446)  loss_objectness: 0.0467 (0.0699)  loss_rpn_box_reg: 0.0338 (0.0569)  time: 1.8443  data: 0.0286  max mem: 7643\n",
      "Epoch: [1]  [140/301]  eta: 0:03:14  lr: 0.005000  loss: 0.1422 (0.2151)  loss_classifier: 0.0375 (0.0456)  loss_box_reg: 0.0355 (0.0443)  loss_objectness: 0.0351 (0.0687)  loss_rpn_box_reg: 0.0346 (0.0565)  time: 0.4505  data: 0.0213  max mem: 7643\n",
      "Epoch: [1]  [150/301]  eta: 0:03:09  lr: 0.005000  loss: 0.1563 (0.2160)  loss_classifier: 0.0375 (0.0453)  loss_box_reg: 0.0413 (0.0442)  loss_objectness: 0.0477 (0.0693)  loss_rpn_box_reg: 0.0427 (0.0571)  time: 1.1571  data: 0.0179  max mem: 7643\n",
      "Epoch: [1]  [160/301]  eta: 0:03:13  lr: 0.005000  loss: 0.1695 (0.2125)  loss_classifier: 0.0388 (0.0447)  loss_box_reg: 0.0371 (0.0437)  loss_objectness: 0.0518 (0.0683)  loss_rpn_box_reg: 0.0334 (0.0558)  time: 2.5448  data: 0.0225  max mem: 7643\n",
      "Epoch: [1]  [170/301]  eta: 0:02:52  lr: 0.005000  loss: 0.1412 (0.2108)  loss_classifier: 0.0361 (0.0442)  loss_box_reg: 0.0353 (0.0433)  loss_objectness: 0.0472 (0.0675)  loss_rpn_box_reg: 0.0227 (0.0559)  time: 1.7848  data: 0.0199  max mem: 7643\n",
      "Epoch: [1]  [180/301]  eta: 0:02:33  lr: 0.005000  loss: 0.1357 (0.2070)  loss_classifier: 0.0361 (0.0438)  loss_box_reg: 0.0344 (0.0427)  loss_objectness: 0.0451 (0.0665)  loss_rpn_box_reg: 0.0197 (0.0541)  time: 0.4687  data: 0.0127  max mem: 7643\n",
      "Epoch: [1]  [190/301]  eta: 0:02:23  lr: 0.005000  loss: 0.1313 (0.2033)  loss_classifier: 0.0310 (0.0431)  loss_box_reg: 0.0316 (0.0420)  loss_objectness: 0.0414 (0.0652)  loss_rpn_box_reg: 0.0206 (0.0530)  time: 1.0831  data: 0.0144  max mem: 7643\n",
      "Epoch: [1]  [200/301]  eta: 0:02:12  lr: 0.005000  loss: 0.1313 (0.2024)  loss_classifier: 0.0310 (0.0425)  loss_box_reg: 0.0306 (0.0415)  loss_objectness: 0.0424 (0.0645)  loss_rpn_box_reg: 0.0296 (0.0539)  time: 1.6661  data: 0.0173  max mem: 7643\n",
      "Epoch: [1]  [210/301]  eta: 0:01:55  lr: 0.005000  loss: 0.1483 (0.2007)  loss_classifier: 0.0324 (0.0422)  loss_box_reg: 0.0344 (0.0415)  loss_objectness: 0.0429 (0.0635)  loss_rpn_box_reg: 0.0393 (0.0536)  time: 1.0888  data: 0.0199  max mem: 7643\n",
      "Epoch: [1]  [220/301]  eta: 0:01:47  lr: 0.005000  loss: 0.1483 (0.1981)  loss_classifier: 0.0336 (0.0418)  loss_box_reg: 0.0357 (0.0413)  loss_objectness: 0.0422 (0.0624)  loss_rpn_box_reg: 0.0388 (0.0526)  time: 1.4335  data: 0.0169  max mem: 7643\n",
      "Epoch: [1]  [230/301]  eta: 0:01:31  lr: 0.005000  loss: 0.1420 (0.1964)  loss_classifier: 0.0320 (0.0415)  loss_box_reg: 0.0315 (0.0409)  loss_objectness: 0.0411 (0.0617)  loss_rpn_box_reg: 0.0360 (0.0523)  time: 1.4568  data: 0.0192  max mem: 7643\n",
      "Epoch: [1]  [240/301]  eta: 0:01:16  lr: 0.005000  loss: 0.1283 (0.1953)  loss_classifier: 0.0291 (0.0411)  loss_box_reg: 0.0299 (0.0406)  loss_objectness: 0.0409 (0.0615)  loss_rpn_box_reg: 0.0360 (0.0521)  time: 0.4624  data: 0.0191  max mem: 7643\n",
      "Epoch: [1]  [250/301]  eta: 0:01:02  lr: 0.005000  loss: 0.1177 (0.1932)  loss_classifier: 0.0259 (0.0407)  loss_box_reg: 0.0287 (0.0401)  loss_objectness: 0.0478 (0.0611)  loss_rpn_box_reg: 0.0242 (0.0513)  time: 0.4822  data: 0.0146  max mem: 7643\n",
      "Epoch: [1]  [260/301]  eta: 0:00:49  lr: 0.005000  loss: 0.1423 (0.1924)  loss_classifier: 0.0285 (0.0403)  loss_box_reg: 0.0287 (0.0398)  loss_objectness: 0.0564 (0.0610)  loss_rpn_box_reg: 0.0232 (0.0513)  time: 0.6648  data: 0.0153  max mem: 7643\n",
      "Epoch: [1]  [270/301]  eta: 0:00:36  lr: 0.005000  loss: 0.1429 (0.1915)  loss_classifier: 0.0291 (0.0400)  loss_box_reg: 0.0316 (0.0395)  loss_objectness: 0.0527 (0.0609)  loss_rpn_box_reg: 0.0354 (0.0511)  time: 0.6844  data: 0.0218  max mem: 7643\n",
      "Epoch: [1]  [280/301]  eta: 0:00:24  lr: 0.005000  loss: 0.1284 (0.1889)  loss_classifier: 0.0287 (0.0397)  loss_box_reg: 0.0316 (0.0392)  loss_objectness: 0.0384 (0.0600)  loss_rpn_box_reg: 0.0235 (0.0500)  time: 0.8309  data: 0.0267  max mem: 7643\n",
      "Epoch: [1]  [290/301]  eta: 0:00:12  lr: 0.005000  loss: 0.1224 (0.1890)  loss_classifier: 0.0313 (0.0395)  loss_box_reg: 0.0329 (0.0390)  loss_objectness: 0.0384 (0.0606)  loss_rpn_box_reg: 0.0204 (0.0498)  time: 0.7447  data: 0.0224  max mem: 7643\n",
      "Epoch: [1]  [300/301]  eta: 0:00:01  lr: 0.005000  loss: 0.1320 (0.1884)  loss_classifier: 0.0321 (0.0392)  loss_box_reg: 0.0271 (0.0386)  loss_objectness: 0.0427 (0.0606)  loss_rpn_box_reg: 0.0250 (0.0500)  time: 1.1838  data: 0.0159  max mem: 7643\n",
      "Epoch: [1] Total time: 0:05:55 (1.1795 s / it)\n",
      "IoU: 0.8117440342903137, mAP: 0.9281957745552063\n",
      "Epoch: [2]  [  0/301]  eta: 0:10:25  lr: 0.005000  loss: 0.1077 (0.1077)  loss_classifier: 0.0271 (0.0271)  loss_box_reg: 0.0297 (0.0297)  loss_objectness: 0.0174 (0.0174)  loss_rpn_box_reg: 0.0335 (0.0335)  time: 2.0785  data: 0.0210  max mem: 7643\n",
      "Epoch: [2]  [ 10/301]  eta: 0:15:52  lr: 0.005000  loss: 0.1432 (0.1410)  loss_classifier: 0.0256 (0.0270)  loss_box_reg: 0.0310 (0.0319)  loss_objectness: 0.0426 (0.0408)  loss_rpn_box_reg: 0.0478 (0.0412)  time: 3.2731  data: 0.0220  max mem: 7643\n",
      "Epoch: [2]  [ 20/301]  eta: 0:09:08  lr: 0.005000  loss: 0.1472 (0.1609)  loss_classifier: 0.0256 (0.0296)  loss_box_reg: 0.0311 (0.0329)  loss_objectness: 0.0434 (0.0478)  loss_rpn_box_reg: 0.0341 (0.0507)  time: 1.9469  data: 0.0204  max mem: 7643\n",
      "Epoch: [2]  [ 30/301]  eta: 0:09:05  lr: 0.005000  loss: 0.1288 (0.1569)  loss_classifier: 0.0254 (0.0284)  loss_box_reg: 0.0289 (0.0304)  loss_objectness: 0.0385 (0.0474)  loss_rpn_box_reg: 0.0296 (0.0507)  time: 1.3194  data: 0.0205  max mem: 7643\n",
      "Epoch: [2]  [ 40/301]  eta: 0:07:24  lr: 0.005000  loss: 0.1184 (0.1528)  loss_classifier: 0.0247 (0.0276)  loss_box_reg: 0.0263 (0.0297)  loss_objectness: 0.0361 (0.0454)  loss_rpn_box_reg: 0.0296 (0.0500)  time: 1.4376  data: 0.0189  max mem: 7643\n",
      "Epoch: [2]  [ 50/301]  eta: 0:06:12  lr: 0.005000  loss: 0.1243 (0.1538)  loss_classifier: 0.0279 (0.0289)  loss_box_reg: 0.0272 (0.0302)  loss_objectness: 0.0340 (0.0459)  loss_rpn_box_reg: 0.0270 (0.0487)  time: 0.6696  data: 0.0185  max mem: 7643\n",
      "Epoch: [2]  [ 60/301]  eta: 0:05:25  lr: 0.005000  loss: 0.1343 (0.1584)  loss_classifier: 0.0309 (0.0291)  loss_box_reg: 0.0308 (0.0306)  loss_objectness: 0.0384 (0.0480)  loss_rpn_box_reg: 0.0247 (0.0506)  time: 0.6339  data: 0.0205  max mem: 7643\n",
      "Epoch: [2]  [ 70/301]  eta: 0:06:11  lr: 0.005000  loss: 0.1273 (0.1523)  loss_classifier: 0.0260 (0.0285)  loss_box_reg: 0.0310 (0.0303)  loss_objectness: 0.0405 (0.0462)  loss_rpn_box_reg: 0.0234 (0.0472)  time: 1.9164  data: 0.0209  max mem: 7643\n",
      "Epoch: [2]  [ 80/301]  eta: 0:05:27  lr: 0.005000  loss: 0.1110 (0.1515)  loss_classifier: 0.0220 (0.0283)  loss_box_reg: 0.0279 (0.0306)  loss_objectness: 0.0333 (0.0456)  loss_rpn_box_reg: 0.0234 (0.0470)  time: 1.8854  data: 0.0187  max mem: 7643\n",
      "Epoch: [2]  [ 90/301]  eta: 0:05:05  lr: 0.005000  loss: 0.1152 (0.1527)  loss_classifier: 0.0254 (0.0286)  loss_box_reg: 0.0280 (0.0308)  loss_objectness: 0.0363 (0.0466)  loss_rpn_box_reg: 0.0360 (0.0468)  time: 0.8725  data: 0.0228  max mem: 7643\n",
      "Epoch: [2]  [100/301]  eta: 0:04:35  lr: 0.005000  loss: 0.1228 (0.1511)  loss_classifier: 0.0254 (0.0288)  loss_box_reg: 0.0284 (0.0313)  loss_objectness: 0.0352 (0.0458)  loss_rpn_box_reg: 0.0297 (0.0451)  time: 0.9213  data: 0.0291  max mem: 7643\n",
      "Epoch: [2]  [110/301]  eta: 0:04:13  lr: 0.005000  loss: 0.1174 (0.1498)  loss_classifier: 0.0224 (0.0288)  loss_box_reg: 0.0284 (0.0315)  loss_objectness: 0.0318 (0.0454)  loss_rpn_box_reg: 0.0262 (0.0440)  time: 0.7942  data: 0.0217  max mem: 7643\n",
      "Epoch: [2]  [120/301]  eta: 0:03:47  lr: 0.005000  loss: 0.1183 (0.1485)  loss_classifier: 0.0274 (0.0292)  loss_box_reg: 0.0290 (0.0316)  loss_objectness: 0.0350 (0.0445)  loss_rpn_box_reg: 0.0307 (0.0433)  time: 0.6808  data: 0.0177  max mem: 7643\n",
      "Epoch: [2]  [130/301]  eta: 0:03:23  lr: 0.005000  loss: 0.1365 (0.1500)  loss_classifier: 0.0259 (0.0292)  loss_box_reg: 0.0296 (0.0318)  loss_objectness: 0.0350 (0.0451)  loss_rpn_box_reg: 0.0262 (0.0439)  time: 0.4402  data: 0.0168  max mem: 7643\n",
      "Epoch: [2]  [140/301]  eta: 0:03:02  lr: 0.005000  loss: 0.1365 (0.1497)  loss_classifier: 0.0288 (0.0292)  loss_box_reg: 0.0315 (0.0317)  loss_objectness: 0.0353 (0.0454)  loss_rpn_box_reg: 0.0262 (0.0434)  time: 0.4005  data: 0.0137  max mem: 7643\n",
      "Epoch: [2]  [150/301]  eta: 0:02:48  lr: 0.005000  loss: 0.1341 (0.1490)  loss_classifier: 0.0285 (0.0294)  loss_box_reg: 0.0292 (0.0318)  loss_objectness: 0.0408 (0.0452)  loss_rpn_box_reg: 0.0246 (0.0426)  time: 0.6209  data: 0.0195  max mem: 7643\n",
      "Epoch: [2]  [160/301]  eta: 0:02:34  lr: 0.005000  loss: 0.1288 (0.1488)  loss_classifier: 0.0262 (0.0296)  loss_box_reg: 0.0281 (0.0320)  loss_objectness: 0.0388 (0.0447)  loss_rpn_box_reg: 0.0257 (0.0425)  time: 0.8378  data: 0.0275  max mem: 7643\n",
      "Epoch: [2]  [170/301]  eta: 0:02:24  lr: 0.005000  loss: 0.1281 (0.1483)  loss_classifier: 0.0239 (0.0298)  loss_box_reg: 0.0299 (0.0325)  loss_objectness: 0.0361 (0.0441)  loss_rpn_box_reg: 0.0299 (0.0420)  time: 1.0122  data: 0.0359  max mem: 7643\n",
      "Epoch: [2]  [180/301]  eta: 0:02:13  lr: 0.005000  loss: 0.1253 (0.1479)  loss_classifier: 0.0274 (0.0299)  loss_box_reg: 0.0322 (0.0325)  loss_objectness: 0.0341 (0.0442)  loss_rpn_box_reg: 0.0253 (0.0413)  time: 1.1355  data: 0.0320  max mem: 7643\n",
      "Epoch: [2]  [190/301]  eta: 0:01:59  lr: 0.005000  loss: 0.1184 (0.1471)  loss_classifier: 0.0267 (0.0300)  loss_box_reg: 0.0292 (0.0324)  loss_objectness: 0.0323 (0.0440)  loss_rpn_box_reg: 0.0214 (0.0407)  time: 0.7958  data: 0.0198  max mem: 7643\n",
      "Epoch: [2]  [200/301]  eta: 0:01:45  lr: 0.005000  loss: 0.1171 (0.1454)  loss_classifier: 0.0227 (0.0296)  loss_box_reg: 0.0255 (0.0320)  loss_objectness: 0.0288 (0.0433)  loss_rpn_box_reg: 0.0259 (0.0405)  time: 0.5402  data: 0.0157  max mem: 7643\n",
      "Epoch: [2]  [210/301]  eta: 0:01:34  lr: 0.005000  loss: 0.0983 (0.1438)  loss_classifier: 0.0226 (0.0293)  loss_box_reg: 0.0251 (0.0317)  loss_objectness: 0.0229 (0.0425)  loss_rpn_box_reg: 0.0281 (0.0403)  time: 0.6579  data: 0.0140  max mem: 7643\n",
      "Epoch: [2]  [220/301]  eta: 0:01:24  lr: 0.005000  loss: 0.0983 (0.1440)  loss_classifier: 0.0200 (0.0290)  loss_box_reg: 0.0266 (0.0316)  loss_objectness: 0.0311 (0.0428)  loss_rpn_box_reg: 0.0330 (0.0407)  time: 0.9995  data: 0.0282  max mem: 7643\n",
      "Epoch: [2]  [230/301]  eta: 0:01:12  lr: 0.005000  loss: 0.1277 (0.1431)  loss_classifier: 0.0191 (0.0286)  loss_box_reg: 0.0260 (0.0314)  loss_objectness: 0.0311 (0.0423)  loss_rpn_box_reg: 0.0353 (0.0408)  time: 0.8204  data: 0.0274  max mem: 7643\n",
      "Epoch: [2]  [240/301]  eta: 0:01:00  lr: 0.005000  loss: 0.1194 (0.1421)  loss_classifier: 0.0196 (0.0285)  loss_box_reg: 0.0251 (0.0311)  loss_objectness: 0.0251 (0.0417)  loss_rpn_box_reg: 0.0354 (0.0408)  time: 0.4438  data: 0.0161  max mem: 7643\n",
      "Epoch: [2]  [250/301]  eta: 0:00:49  lr: 0.005000  loss: 0.1147 (0.1416)  loss_classifier: 0.0256 (0.0285)  loss_box_reg: 0.0253 (0.0310)  loss_objectness: 0.0300 (0.0415)  loss_rpn_box_reg: 0.0317 (0.0405)  time: 0.5382  data: 0.0250  max mem: 7643\n",
      "Epoch: [2]  [260/301]  eta: 0:00:41  lr: 0.005000  loss: 0.1068 (0.1405)  loss_classifier: 0.0197 (0.0282)  loss_box_reg: 0.0269 (0.0308)  loss_objectness: 0.0328 (0.0412)  loss_rpn_box_reg: 0.0277 (0.0402)  time: 1.2353  data: 0.0278  max mem: 7643\n",
      "Epoch: [2]  [270/301]  eta: 0:00:30  lr: 0.005000  loss: 0.0961 (0.1389)  loss_classifier: 0.0197 (0.0281)  loss_box_reg: 0.0263 (0.0306)  loss_objectness: 0.0236 (0.0406)  loss_rpn_box_reg: 0.0260 (0.0396)  time: 1.2682  data: 0.0215  max mem: 7643\n",
      "Epoch: [2]  [280/301]  eta: 0:00:21  lr: 0.005000  loss: 0.0961 (0.1375)  loss_classifier: 0.0216 (0.0280)  loss_box_reg: 0.0258 (0.0305)  loss_objectness: 0.0199 (0.0400)  loss_rpn_box_reg: 0.0237 (0.0391)  time: 0.8490  data: 0.0192  max mem: 7643\n",
      "Epoch: [2]  [290/301]  eta: 0:00:11  lr: 0.005000  loss: 0.0877 (0.1360)  loss_classifier: 0.0191 (0.0278)  loss_box_reg: 0.0218 (0.0304)  loss_objectness: 0.0225 (0.0395)  loss_rpn_box_reg: 0.0175 (0.0384)  time: 1.1036  data: 0.0172  max mem: 7643\n",
      "Epoch: [2]  [300/301]  eta: 0:00:00  lr: 0.005000  loss: 0.0985 (0.1357)  loss_classifier: 0.0257 (0.0279)  loss_box_reg: 0.0227 (0.0303)  loss_objectness: 0.0227 (0.0394)  loss_rpn_box_reg: 0.0169 (0.0382)  time: 0.7921  data: 0.0135  max mem: 7643\n",
      "Epoch: [2] Total time: 0:04:56 (0.9864 s / it)\n",
      "IoU: 0.8586409687995911, mAP: 0.9517179727554321\n",
      "Epoch: [3]  [  0/301]  eta: 0:02:04  lr: 0.000500  loss: 0.0856 (0.0856)  loss_classifier: 0.0279 (0.0279)  loss_box_reg: 0.0257 (0.0257)  loss_objectness: 0.0114 (0.0114)  loss_rpn_box_reg: 0.0205 (0.0205)  time: 0.4124  data: 0.0267  max mem: 7643\n",
      "Epoch: [3]  [ 10/301]  eta: 0:02:02  lr: 0.000500  loss: 0.0778 (0.0979)  loss_classifier: 0.0203 (0.0249)  loss_box_reg: 0.0247 (0.0245)  loss_objectness: 0.0140 (0.0208)  loss_rpn_box_reg: 0.0205 (0.0277)  time: 0.4195  data: 0.0155  max mem: 7643\n",
      "Epoch: [3]  [ 20/301]  eta: 0:01:56  lr: 0.000500  loss: 0.0778 (0.0997)  loss_classifier: 0.0203 (0.0245)  loss_box_reg: 0.0237 (0.0259)  loss_objectness: 0.0170 (0.0239)  loss_rpn_box_reg: 0.0172 (0.0253)  time: 0.4154  data: 0.0137  max mem: 7643\n",
      "Epoch: [3]  [ 30/301]  eta: 0:01:53  lr: 0.000500  loss: 0.0932 (0.1027)  loss_classifier: 0.0213 (0.0244)  loss_box_reg: 0.0230 (0.0256)  loss_objectness: 0.0253 (0.0254)  loss_rpn_box_reg: 0.0191 (0.0274)  time: 0.4174  data: 0.0135  max mem: 7643\n",
      "Epoch: [3]  [ 40/301]  eta: 0:02:29  lr: 0.000500  loss: 0.1002 (0.1054)  loss_classifier: 0.0167 (0.0239)  loss_box_reg: 0.0226 (0.0262)  loss_objectness: 0.0225 (0.0258)  loss_rpn_box_reg: 0.0243 (0.0295)  time: 0.7363  data: 0.0239  max mem: 7643\n",
      "Epoch: [3]  [ 50/301]  eta: 0:02:17  lr: 0.000500  loss: 0.0863 (0.1022)  loss_classifier: 0.0169 (0.0230)  loss_box_reg: 0.0223 (0.0255)  loss_objectness: 0.0185 (0.0246)  loss_rpn_box_reg: 0.0230 (0.0291)  time: 0.7460  data: 0.0243  max mem: 7643\n",
      "Epoch: [3]  [ 60/301]  eta: 0:03:14  lr: 0.000500  loss: 0.0897 (0.1107)  loss_classifier: 0.0212 (0.0234)  loss_box_reg: 0.0243 (0.0258)  loss_objectness: 0.0199 (0.0316)  loss_rpn_box_reg: 0.0165 (0.0299)  time: 1.2896  data: 0.0182  max mem: 7643\n",
      "Epoch: [3]  [ 70/301]  eta: 0:03:43  lr: 0.000500  loss: 0.0925 (0.1151)  loss_classifier: 0.0203 (0.0235)  loss_box_reg: 0.0269 (0.0265)  loss_objectness: 0.0243 (0.0340)  loss_rpn_box_reg: 0.0231 (0.0312)  time: 2.0348  data: 0.0202  max mem: 7643\n",
      "Epoch: [3]  [ 80/301]  eta: 0:03:25  lr: 0.000500  loss: 0.0864 (0.1125)  loss_classifier: 0.0193 (0.0231)  loss_box_reg: 0.0221 (0.0260)  loss_objectness: 0.0251 (0.0335)  loss_rpn_box_reg: 0.0199 (0.0300)  time: 1.2968  data: 0.0254  max mem: 7643\n",
      "Epoch: [3]  [ 90/301]  eta: 0:03:16  lr: 0.000500  loss: 0.0864 (0.1119)  loss_classifier: 0.0196 (0.0229)  loss_box_reg: 0.0219 (0.0257)  loss_objectness: 0.0280 (0.0332)  loss_rpn_box_reg: 0.0173 (0.0300)  time: 0.8164  data: 0.0269  max mem: 7643\n",
      "Epoch: [3]  [100/301]  eta: 0:03:26  lr: 0.000500  loss: 0.0817 (0.1098)  loss_classifier: 0.0196 (0.0226)  loss_box_reg: 0.0240 (0.0257)  loss_objectness: 0.0226 (0.0322)  loss_rpn_box_reg: 0.0211 (0.0292)  time: 1.4301  data: 0.0246  max mem: 7643\n",
      "Epoch: [3]  [110/301]  eta: 0:03:38  lr: 0.000500  loss: 0.0807 (0.1103)  loss_classifier: 0.0212 (0.0229)  loss_box_reg: 0.0249 (0.0264)  loss_objectness: 0.0215 (0.0321)  loss_rpn_box_reg: 0.0211 (0.0289)  time: 2.1086  data: 0.0215  max mem: 7643\n",
      "Epoch: [3]  [120/301]  eta: 0:03:18  lr: 0.000500  loss: 0.0986 (0.1120)  loss_classifier: 0.0209 (0.0229)  loss_box_reg: 0.0275 (0.0266)  loss_objectness: 0.0277 (0.0329)  loss_rpn_box_reg: 0.0220 (0.0297)  time: 1.4537  data: 0.0208  max mem: 7643\n",
      "Epoch: [3]  [130/301]  eta: 0:03:19  lr: 0.000500  loss: 0.0922 (0.1106)  loss_classifier: 0.0202 (0.0230)  loss_box_reg: 0.0260 (0.0265)  loss_objectness: 0.0205 (0.0322)  loss_rpn_box_reg: 0.0183 (0.0289)  time: 1.2955  data: 0.0214  max mem: 7643\n",
      "Epoch: [3]  [140/301]  eta: 0:03:01  lr: 0.000500  loss: 0.0922 (0.1109)  loss_classifier: 0.0186 (0.0229)  loss_box_reg: 0.0258 (0.0267)  loss_objectness: 0.0229 (0.0323)  loss_rpn_box_reg: 0.0183 (0.0290)  time: 1.3076  data: 0.0192  max mem: 7643\n",
      "Epoch: [3]  [150/301]  eta: 0:02:46  lr: 0.000500  loss: 0.1000 (0.1102)  loss_classifier: 0.0186 (0.0227)  loss_box_reg: 0.0274 (0.0267)  loss_objectness: 0.0265 (0.0321)  loss_rpn_box_reg: 0.0241 (0.0287)  time: 0.6891  data: 0.0240  max mem: 7643\n",
      "Epoch: [3]  [160/301]  eta: 0:02:30  lr: 0.000500  loss: 0.1000 (0.1114)  loss_classifier: 0.0200 (0.0233)  loss_box_reg: 0.0284 (0.0271)  loss_objectness: 0.0305 (0.0325)  loss_rpn_box_reg: 0.0219 (0.0285)  time: 0.6494  data: 0.0300  max mem: 7643\n",
      "Epoch: [3]  [170/301]  eta: 0:02:25  lr: 0.000500  loss: 0.0944 (0.1108)  loss_classifier: 0.0200 (0.0232)  loss_box_reg: 0.0255 (0.0271)  loss_objectness: 0.0305 (0.0320)  loss_rpn_box_reg: 0.0188 (0.0285)  time: 1.1289  data: 0.0237  max mem: 7643\n",
      "Epoch: [3]  [180/301]  eta: 0:02:11  lr: 0.000500  loss: 0.0902 (0.1104)  loss_classifier: 0.0186 (0.0232)  loss_box_reg: 0.0231 (0.0268)  loss_objectness: 0.0299 (0.0321)  loss_rpn_box_reg: 0.0188 (0.0282)  time: 1.2102  data: 0.0231  max mem: 7643\n",
      "Epoch: [3]  [190/301]  eta: 0:01:56  lr: 0.000500  loss: 0.0966 (0.1102)  loss_classifier: 0.0222 (0.0234)  loss_box_reg: 0.0223 (0.0267)  loss_objectness: 0.0315 (0.0321)  loss_rpn_box_reg: 0.0192 (0.0280)  time: 0.5555  data: 0.0225  max mem: 7643\n",
      "Epoch: [3]  [200/301]  eta: 0:01:42  lr: 0.000500  loss: 0.0926 (0.1098)  loss_classifier: 0.0198 (0.0231)  loss_box_reg: 0.0224 (0.0266)  loss_objectness: 0.0255 (0.0319)  loss_rpn_box_reg: 0.0192 (0.0283)  time: 0.4165  data: 0.0128  max mem: 7643\n",
      "Epoch: [3]  [210/301]  eta: 0:01:35  lr: 0.000500  loss: 0.0930 (0.1109)  loss_classifier: 0.0198 (0.0233)  loss_box_reg: 0.0229 (0.0268)  loss_objectness: 0.0278 (0.0321)  loss_rpn_box_reg: 0.0217 (0.0287)  time: 1.0383  data: 0.0215  max mem: 7643\n",
      "Epoch: [3]  [220/301]  eta: 0:01:24  lr: 0.000500  loss: 0.1061 (0.1113)  loss_classifier: 0.0219 (0.0235)  loss_box_reg: 0.0279 (0.0270)  loss_objectness: 0.0265 (0.0321)  loss_rpn_box_reg: 0.0238 (0.0287)  time: 1.3633  data: 0.0216  max mem: 7643\n",
      "Epoch: [3]  [230/301]  eta: 0:01:14  lr: 0.000500  loss: 0.0998 (0.1113)  loss_classifier: 0.0219 (0.0238)  loss_box_reg: 0.0294 (0.0272)  loss_objectness: 0.0220 (0.0319)  loss_rpn_box_reg: 0.0238 (0.0285)  time: 0.9958  data: 0.0180  max mem: 7643\n",
      "Epoch: [3]  [240/301]  eta: 0:01:02  lr: 0.000500  loss: 0.0985 (0.1110)  loss_classifier: 0.0218 (0.0236)  loss_box_reg: 0.0225 (0.0271)  loss_objectness: 0.0228 (0.0318)  loss_rpn_box_reg: 0.0239 (0.0285)  time: 0.8084  data: 0.0206  max mem: 7643\n",
      "Epoch: [3]  [250/301]  eta: 0:00:52  lr: 0.000500  loss: 0.0933 (0.1109)  loss_classifier: 0.0200 (0.0235)  loss_box_reg: 0.0225 (0.0270)  loss_objectness: 0.0209 (0.0320)  loss_rpn_box_reg: 0.0218 (0.0284)  time: 0.8242  data: 0.0207  max mem: 7643\n",
      "Epoch: [3]  [260/301]  eta: 0:00:41  lr: 0.000500  loss: 0.0975 (0.1115)  loss_classifier: 0.0200 (0.0239)  loss_box_reg: 0.0250 (0.0273)  loss_objectness: 0.0244 (0.0321)  loss_rpn_box_reg: 0.0216 (0.0283)  time: 0.7680  data: 0.0228  max mem: 7643\n",
      "Epoch: [3]  [270/301]  eta: 0:00:30  lr: 0.000500  loss: 0.0896 (0.1105)  loss_classifier: 0.0194 (0.0237)  loss_box_reg: 0.0255 (0.0272)  loss_objectness: 0.0243 (0.0316)  loss_rpn_box_reg: 0.0216 (0.0280)  time: 0.6173  data: 0.0216  max mem: 7643\n",
      "Epoch: [3]  [280/301]  eta: 0:00:20  lr: 0.000500  loss: 0.0870 (0.1100)  loss_classifier: 0.0180 (0.0235)  loss_box_reg: 0.0233 (0.0271)  loss_objectness: 0.0218 (0.0314)  loss_rpn_box_reg: 0.0265 (0.0280)  time: 0.5891  data: 0.0215  max mem: 7643\n",
      "Epoch: [3]  [290/301]  eta: 0:00:10  lr: 0.000500  loss: 0.0926 (0.1099)  loss_classifier: 0.0204 (0.0237)  loss_box_reg: 0.0233 (0.0273)  loss_objectness: 0.0256 (0.0311)  loss_rpn_box_reg: 0.0258 (0.0278)  time: 0.4998  data: 0.0187  max mem: 7643\n",
      "Epoch: [3]  [300/301]  eta: 0:00:00  lr: 0.000500  loss: 0.0929 (0.1100)  loss_classifier: 0.0206 (0.0237)  loss_box_reg: 0.0290 (0.0273)  loss_objectness: 0.0256 (0.0311)  loss_rpn_box_reg: 0.0169 (0.0280)  time: 0.5064  data: 0.0166  max mem: 7643\n",
      "Epoch: [3] Total time: 0:04:45 (0.9477 s / it)\n",
      "IoU: 0.8766075968742371, mAP: 0.9777669906616211\n",
      "Epoch: [4]  [  0/301]  eta: 0:02:16  lr: 0.000500  loss: 0.1623 (0.1623)  loss_classifier: 0.0530 (0.0530)  loss_box_reg: 0.0411 (0.0411)  loss_objectness: 0.0491 (0.0491)  loss_rpn_box_reg: 0.0191 (0.0191)  time: 0.4550  data: 0.0180  max mem: 7643\n",
      "Epoch: [4]  [ 10/301]  eta: 0:11:14  lr: 0.000500  loss: 0.0986 (0.1048)  loss_classifier: 0.0225 (0.0266)  loss_box_reg: 0.0229 (0.0269)  loss_objectness: 0.0302 (0.0306)  loss_rpn_box_reg: 0.0191 (0.0207)  time: 2.3179  data: 0.0239  max mem: 7643\n",
      "Epoch: [4]  [ 20/301]  eta: 0:07:59  lr: 0.000500  loss: 0.0953 (0.1053)  loss_classifier: 0.0216 (0.0256)  loss_box_reg: 0.0258 (0.0278)  loss_objectness: 0.0239 (0.0274)  loss_rpn_box_reg: 0.0240 (0.0245)  time: 1.7684  data: 0.0229  max mem: 7643\n",
      "Epoch: [4]  [ 30/301]  eta: 0:06:26  lr: 0.000500  loss: 0.0979 (0.1075)  loss_classifier: 0.0214 (0.0238)  loss_box_reg: 0.0270 (0.0273)  loss_objectness: 0.0217 (0.0281)  loss_rpn_box_reg: 0.0263 (0.0283)  time: 0.9349  data: 0.0205  max mem: 7643\n",
      "Epoch: [4]  [ 40/301]  eta: 0:05:22  lr: 0.000500  loss: 0.0993 (0.1045)  loss_classifier: 0.0207 (0.0231)  loss_box_reg: 0.0217 (0.0257)  loss_objectness: 0.0237 (0.0280)  loss_rpn_box_reg: 0.0280 (0.0277)  time: 0.7427  data: 0.0236  max mem: 7643\n",
      "Epoch: [4]  [ 50/301]  eta: 0:04:48  lr: 0.000500  loss: 0.0988 (0.1026)  loss_classifier: 0.0170 (0.0223)  loss_box_reg: 0.0213 (0.0258)  loss_objectness: 0.0243 (0.0275)  loss_rpn_box_reg: 0.0211 (0.0270)  time: 0.7219  data: 0.0242  max mem: 7643\n",
      "Epoch: [4]  [ 60/301]  eta: 0:04:26  lr: 0.000500  loss: 0.0870 (0.1014)  loss_classifier: 0.0170 (0.0223)  loss_box_reg: 0.0226 (0.0256)  loss_objectness: 0.0250 (0.0271)  loss_rpn_box_reg: 0.0204 (0.0265)  time: 0.8444  data: 0.0260  max mem: 7643\n",
      "Epoch: [4]  [ 70/301]  eta: 0:03:57  lr: 0.000500  loss: 0.0870 (0.1029)  loss_classifier: 0.0163 (0.0217)  loss_box_reg: 0.0226 (0.0253)  loss_objectness: 0.0250 (0.0284)  loss_rpn_box_reg: 0.0182 (0.0275)  time: 0.7152  data: 0.0258  max mem: 7643\n",
      "Epoch: [4]  [ 80/301]  eta: 0:03:41  lr: 0.000500  loss: 0.0983 (0.1043)  loss_classifier: 0.0167 (0.0224)  loss_box_reg: 0.0246 (0.0262)  loss_objectness: 0.0222 (0.0285)  loss_rpn_box_reg: 0.0182 (0.0272)  time: 0.6729  data: 0.0223  max mem: 7643\n",
      "Epoch: [4]  [ 90/301]  eta: 0:03:19  lr: 0.000500  loss: 0.1001 (0.1059)  loss_classifier: 0.0207 (0.0227)  loss_box_reg: 0.0253 (0.0263)  loss_objectness: 0.0280 (0.0295)  loss_rpn_box_reg: 0.0210 (0.0274)  time: 0.6506  data: 0.0273  max mem: 7643\n",
      "Epoch: [4]  [100/301]  eta: 0:02:59  lr: 0.000500  loss: 0.1009 (0.1051)  loss_classifier: 0.0228 (0.0228)  loss_box_reg: 0.0253 (0.0264)  loss_objectness: 0.0285 (0.0289)  loss_rpn_box_reg: 0.0213 (0.0270)  time: 0.4564  data: 0.0216  max mem: 7643\n",
      "Epoch: [4]  [110/301]  eta: 0:02:45  lr: 0.000500  loss: 0.0943 (0.1038)  loss_classifier: 0.0206 (0.0229)  loss_box_reg: 0.0264 (0.0265)  loss_objectness: 0.0228 (0.0283)  loss_rpn_box_reg: 0.0135 (0.0261)  time: 0.5029  data: 0.0162  max mem: 7643\n",
      "Epoch: [4]  [120/301]  eta: 0:02:34  lr: 0.000500  loss: 0.0812 (0.1040)  loss_classifier: 0.0206 (0.0229)  loss_box_reg: 0.0283 (0.0267)  loss_objectness: 0.0188 (0.0282)  loss_rpn_box_reg: 0.0147 (0.0262)  time: 0.6417  data: 0.0230  max mem: 7643\n",
      "Epoch: [4]  [130/301]  eta: 0:02:20  lr: 0.000500  loss: 0.0893 (0.1043)  loss_classifier: 0.0213 (0.0228)  loss_box_reg: 0.0279 (0.0268)  loss_objectness: 0.0190 (0.0283)  loss_rpn_box_reg: 0.0206 (0.0265)  time: 0.5905  data: 0.0193  max mem: 7643\n",
      "Epoch: [4]  [140/301]  eta: 0:02:07  lr: 0.000500  loss: 0.0930 (0.1037)  loss_classifier: 0.0192 (0.0228)  loss_box_reg: 0.0260 (0.0271)  loss_objectness: 0.0272 (0.0279)  loss_rpn_box_reg: 0.0177 (0.0259)  time: 0.4457  data: 0.0178  max mem: 7643\n",
      "Epoch: [4]  [150/301]  eta: 0:01:55  lr: 0.000500  loss: 0.0964 (0.1041)  loss_classifier: 0.0192 (0.0228)  loss_box_reg: 0.0288 (0.0271)  loss_objectness: 0.0229 (0.0281)  loss_rpn_box_reg: 0.0176 (0.0261)  time: 0.4078  data: 0.0191  max mem: 7643\n",
      "Epoch: [4]  [160/301]  eta: 0:01:45  lr: 0.000500  loss: 0.1011 (0.1054)  loss_classifier: 0.0212 (0.0229)  loss_box_reg: 0.0288 (0.0273)  loss_objectness: 0.0247 (0.0286)  loss_rpn_box_reg: 0.0272 (0.0267)  time: 0.4233  data: 0.0169  max mem: 7643\n",
      "Epoch: [4]  [170/301]  eta: 0:01:38  lr: 0.000500  loss: 0.1210 (0.1073)  loss_classifier: 0.0226 (0.0235)  loss_box_reg: 0.0277 (0.0277)  loss_objectness: 0.0316 (0.0290)  loss_rpn_box_reg: 0.0222 (0.0270)  time: 0.6617  data: 0.0170  max mem: 7643\n",
      "Epoch: [4]  [180/301]  eta: 0:01:30  lr: 0.000500  loss: 0.1015 (0.1072)  loss_classifier: 0.0211 (0.0234)  loss_box_reg: 0.0271 (0.0277)  loss_objectness: 0.0320 (0.0293)  loss_rpn_box_reg: 0.0184 (0.0268)  time: 0.7793  data: 0.0190  max mem: 7643\n",
      "Epoch: [4]  [190/301]  eta: 0:01:28  lr: 0.000500  loss: 0.0998 (0.1065)  loss_classifier: 0.0211 (0.0233)  loss_box_reg: 0.0277 (0.0276)  loss_objectness: 0.0242 (0.0290)  loss_rpn_box_reg: 0.0159 (0.0265)  time: 1.1508  data: 0.0174  max mem: 7643\n",
      "Epoch: [4]  [200/301]  eta: 0:01:27  lr: 0.000500  loss: 0.0960 (0.1060)  loss_classifier: 0.0199 (0.0233)  loss_box_reg: 0.0275 (0.0277)  loss_objectness: 0.0242 (0.0289)  loss_rpn_box_reg: 0.0147 (0.0260)  time: 1.8609  data: 0.0166  max mem: 7643\n",
      "Epoch: [4]  [210/301]  eta: 0:01:24  lr: 0.000500  loss: 0.0906 (0.1051)  loss_classifier: 0.0188 (0.0230)  loss_box_reg: 0.0247 (0.0276)  loss_objectness: 0.0233 (0.0285)  loss_rpn_box_reg: 0.0151 (0.0260)  time: 2.1976  data: 0.0167  max mem: 7643\n",
      "Epoch: [4]  [220/301]  eta: 0:01:23  lr: 0.000500  loss: 0.0913 (0.1067)  loss_classifier: 0.0181 (0.0232)  loss_box_reg: 0.0252 (0.0278)  loss_objectness: 0.0233 (0.0292)  loss_rpn_box_reg: 0.0195 (0.0265)  time: 2.6784  data: 0.0203  max mem: 7643\n",
      "Epoch: [4]  [230/301]  eta: 0:01:12  lr: 0.000500  loss: 0.0951 (0.1061)  loss_classifier: 0.0172 (0.0230)  loss_box_reg: 0.0253 (0.0276)  loss_objectness: 0.0217 (0.0291)  loss_rpn_box_reg: 0.0181 (0.0264)  time: 2.0220  data: 0.0233  max mem: 7643\n",
      "Epoch: [4]  [240/301]  eta: 0:01:05  lr: 0.000500  loss: 0.0976 (0.1079)  loss_classifier: 0.0179 (0.0232)  loss_box_reg: 0.0228 (0.0277)  loss_objectness: 0.0221 (0.0303)  loss_rpn_box_reg: 0.0205 (0.0266)  time: 1.5283  data: 0.0194  max mem: 7643\n",
      "Epoch: [4]  [250/301]  eta: 0:00:56  lr: 0.000500  loss: 0.0995 (0.1078)  loss_classifier: 0.0218 (0.0232)  loss_box_reg: 0.0228 (0.0276)  loss_objectness: 0.0304 (0.0304)  loss_rpn_box_reg: 0.0232 (0.0266)  time: 2.1402  data: 0.0216  max mem: 7643\n",
      "Epoch: [4]  [260/301]  eta: 0:00:45  lr: 0.000500  loss: 0.0920 (0.1071)  loss_classifier: 0.0175 (0.0230)  loss_box_reg: 0.0225 (0.0274)  loss_objectness: 0.0236 (0.0301)  loss_rpn_box_reg: 0.0210 (0.0266)  time: 1.5033  data: 0.0247  max mem: 7643\n",
      "Epoch: [4]  [270/301]  eta: 0:00:35  lr: 0.000500  loss: 0.0835 (0.1067)  loss_classifier: 0.0175 (0.0230)  loss_box_reg: 0.0255 (0.0274)  loss_objectness: 0.0180 (0.0298)  loss_rpn_box_reg: 0.0199 (0.0264)  time: 1.3463  data: 0.0271  max mem: 7643\n",
      "Epoch: [4]  [280/301]  eta: 0:00:23  lr: 0.000500  loss: 0.0821 (0.1064)  loss_classifier: 0.0200 (0.0230)  loss_box_reg: 0.0249 (0.0274)  loss_objectness: 0.0170 (0.0296)  loss_rpn_box_reg: 0.0181 (0.0264)  time: 1.4084  data: 0.0238  max mem: 7643\n",
      "Epoch: [4]  [290/301]  eta: 0:00:12  lr: 0.000500  loss: 0.0762 (0.1055)  loss_classifier: 0.0177 (0.0229)  loss_box_reg: 0.0237 (0.0273)  loss_objectness: 0.0183 (0.0294)  loss_rpn_box_reg: 0.0138 (0.0260)  time: 1.3861  data: 0.0205  max mem: 7643\n",
      "Epoch: [4]  [300/301]  eta: 0:00:01  lr: 0.000500  loss: 0.0788 (0.1051)  loss_classifier: 0.0182 (0.0228)  loss_box_reg: 0.0232 (0.0272)  loss_objectness: 0.0206 (0.0293)  loss_rpn_box_reg: 0.0150 (0.0258)  time: 2.5830  data: 0.0177  max mem: 7643\n",
      "Epoch: [4] Total time: 0:06:07 (1.2200 s / it)\n",
      "IoU: 0.874180793762207, mAP: 0.9602044820785522\n",
      "That's it!\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# let's train it just for 2 epochs\n",
    "num_epochs = 5\n",
    "max_IoU = 0\n",
    "history = []\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    logger = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
    "    history.append(logger)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    IoU, mAP = validate(model, val_loader, device=device)\n",
    "    print(f\"IoU: {IoU}, mAP: {mAP}\", )\n",
    "\n",
    "    if IoU > max_IoU:\n",
    "        max_IoU = IoU\n",
    "        model_name = f\"FasterRCNN_MobileNetV3_large_{max_IoU:.3f}.pth\"\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    # evaluate(model, val_loader, device=device)\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Axioo Pongo\\AppData\\Local\\Temp\\ipykernel_10444\\2503380960.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_model.load_state_dict(torch.load('FasterRCNN_MobileNetV3_large_0.877.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "0.93292356\n",
      "[0.84706634 0.5556895  0.31761363 0.31381223 0.24114494 0.20264284\n",
      " 0.09521103 0.0538196 ]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw \n",
    "\n",
    "# predict one image\n",
    "image, target = test_loader.dataset[58]\n",
    "test_model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=2,\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ").to(device)\n",
    "test_model.load_state_dict(torch.load('FasterRCNN_MobileNetV3_large_0.877.pth'))\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = test_model([image.to(device)])[0]\n",
    "\n",
    "    mAP = get_mAP(\n",
    "        prediction[\"boxes\"].cpu(), \n",
    "        prediction[\"labels\"].cpu(), \n",
    "        prediction[\"scores\"].cpu(),\n",
    "          target[\"boxes\"], \n",
    "          target[\"labels\"]\n",
    "          )\n",
    "    print(mAP)\n",
    "    # get the predicted bounding boxes\n",
    "    pred_boxes = prediction[\"boxes\"].cpu().numpy()\n",
    "    # get the predicted labels\n",
    "    pred_labels = prediction[\"labels\"].cpu().numpy()\n",
    "    # get the predicted scores\n",
    "    pred_scores = prediction[\"scores\"].cpu().numpy()\n",
    "    # get the ground truth bounding boxes\n",
    "    gt_boxes = target[\"boxes\"].numpy()\n",
    "    # get the ground truth labels\n",
    "    gt_labels = target[\"labels\"].numpy()\n",
    "    # get the ground truth areas\n",
    "    gt_areas = target[\"area\"].numpy()\n",
    "    # get the ground truth iscrowd\n",
    "    gt_iscrowd = target[\"iscrowd\"].numpy()\n",
    "    # get the ground truth image_id\n",
    "    gt_image_id = target[\"image_id\"].numpy()\n",
    "    # get the IoU\n",
    "    iou = getIoU(pred_boxes[0], gt_boxes[0])\n",
    "    img = Image.fromarray(image.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "    #show bbox\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle([(pred_boxes[0][0], pred_boxes[0][1]), (pred_boxes[0][2], pred_boxes[0][3])], outline =\"red\", width=3)\n",
    "    draw.rectangle([(gt_boxes[0][0], gt_boxes[0][1]), (gt_boxes[0][2], gt_boxes[0][3])], outline =\"green\", width=3)\n",
    "    img.show()\n",
    "\n",
    "    print(iou)\n",
    "    print(pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82474726 tensor(0.8636)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "IoU, mAP = validate(test_model, test_loader, device=device)\n",
    "\n",
    "print(IoU, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import evaluate\n",
    "# evaluate(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import v2 as T\n",
    "\n",
    "# def get_transform(train):\n",
    "#     transforms = []\n",
    "#     if train:\n",
    "#         transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "#     transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "#     transforms.append(T.ToPureTensor())\n",
    "#     return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# criterion = torch.nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import sys\n",
    "# import time\n",
    "\n",
    "# import torch\n",
    "# import torchvision.models.detection.mask_rcnn\n",
    "# import utils\n",
    "# from coco_eval import CocoEvaluator\n",
    "# from coco_utils import get_coco_api_from_dataset\n",
    "\n",
    "\n",
    "# def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, scaler=None):\n",
    "#     model.train()\n",
    "#     metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "#     metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "#     header = f\"Epoch: [{epoch}]\"\n",
    "\n",
    "#     lr_scheduler = None\n",
    "#     if epoch == 0:\n",
    "#         warmup_factor = 1.0 / 1000\n",
    "#         warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "#             optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "#         )\n",
    "\n",
    "#     for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "#         images = list(image.to(device) for image in images)\n",
    "#         targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
    "#         with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "#             loss_dict = model(images, targets)\n",
    "#             losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "#         # reduce losses over all GPUs for logging purposes\n",
    "#         loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "#         losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "#         loss_value = losses_reduced.item()\n",
    "\n",
    "#         if not math.isfinite(loss_value):\n",
    "#             print(f\"Loss is {loss_value}, stopping training\")\n",
    "#             print(loss_dict_reduced)\n",
    "#             sys.exit(1)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         if scaler is not None:\n",
    "#             scaler.scale(losses).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "#         else:\n",
    "#             losses.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         if lr_scheduler is not None:\n",
    "#             lr_scheduler.step()\n",
    "\n",
    "#         metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "#         metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "#     return metric_logger\n",
    "\n",
    "\n",
    "# def _get_iou_types(model):\n",
    "#     model_without_ddp = model\n",
    "#     if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "#         model_without_ddp = model.module\n",
    "#     iou_types = [\"bbox\"]\n",
    "#     if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
    "#         iou_types.append(\"segm\")\n",
    "#     if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
    "#         iou_types.append(\"keypoints\")\n",
    "#     return iou_types\n",
    "\n",
    "\n",
    "# @torch.inference_mode()\n",
    "# def evaluate(model, data_loader, device):\n",
    "#     n_threads = torch.get_num_threads()\n",
    "#     # FIXME remove this and make paste_masks_in_image run on the GPU\n",
    "#     torch.set_num_threads(1)\n",
    "#     cpu_device = torch.device(\"cpu\")\n",
    "#     model.eval()\n",
    "#     metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "#     header = \"Test:\"\n",
    "\n",
    "#     coco = get_coco_api_from_dataset(data_loader.dataset)\n",
    "#     iou_types = _get_iou_types(model)\n",
    "#     coco_evaluator = CocoEvaluator(coco, iou_types)\n",
    "\n",
    "#     for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
    "#         images = list(img.to(device) for img in images)\n",
    "\n",
    "#         if torch.cuda.is_available():\n",
    "#             torch.cuda.synchronize()\n",
    "#         model_time = time.time()\n",
    "#         outputs = model(images)\n",
    "\n",
    "#         outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "#         model_time = time.time() - model_time\n",
    "\n",
    "#         res = {target[\"image_id\"]: output for target, output in zip(targets, outputs)}\n",
    "#         evaluator_time = time.time()\n",
    "#         coco_evaluator.update(res)\n",
    "#         evaluator_time = time.time() - evaluator_time\n",
    "#         metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
    "\n",
    "#     # gather the stats from all processes\n",
    "#     metric_logger.synchronize_between_processes()\n",
    "#     print(\"Averaged stats:\", metric_logger)\n",
    "#     coco_evaluator.synchronize_between_processes()\n",
    "\n",
    "#     # accumulate predictions from all images\n",
    "#     coco_evaluator.accumulate()\n",
    "#     coco_evaluator.summarize()\n",
    "#     torch.set_num_threads(n_threads)\n",
    "#     return coco_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# num_epochs = 10\n",
    "# max_mAP = 0\n",
    "# model_name = ''\n",
    "# date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_one_epoch(model, criterion, optimizer, train_loader, epoch)\n",
    "#     mAP = evaluate(model, val_loader)\n",
    "#     scheduler.step()  # Update learning rate\n",
    "\n",
    "#     if mAP > max_mAP:\n",
    "#         max_mAP = mAP\n",
    "#         model_name = f\"last_MobileNetSSD{date}_{mAP:.3f}.pt\"\n",
    "#         torch.save(model.state_dict(), model_name)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

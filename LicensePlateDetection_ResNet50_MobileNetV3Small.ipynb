{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Detector using MobilenetV3Small SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotation, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.coco = COCO(annotation)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Own coco file\n",
    "        coco = self.coco\n",
    "        # Image ID\n",
    "        img_id = self.ids[index]\n",
    "        # List: get annotation id from coco\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        # Dictionary: target coco_annotation file for an image\n",
    "        coco_annotation = coco.loadAnns(ann_ids)\n",
    "        # path for input image\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        # open the input image\n",
    "        img = Image.open(os.path.join(self.root, path))\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "        # number of objects in the image\n",
    "        num_objs = len(coco_annotation)\n",
    "\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            xmin = coco_annotation[i]['bbox'][0]\n",
    "            ymin = coco_annotation[i]['bbox'][1]\n",
    "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
    "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # Labels (In my case, I only one class: target class or background)\n",
    "        labels = torch.ones(num_objs, dtype=torch.int64)\n",
    "        # Tensorise img_id\n",
    "        img_id = torch.tensor(img_id)\n",
    "        # Size of bbox (Rectangular)\n",
    "        areas = []\n",
    "        for i in range(num_objs):\n",
    "            areas.append(coco_annotation[i]['area'])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        # Iscrowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        if num_objs == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "            areas = torch.zeros((0,), dtype=torch.float32)\n",
    "            iscrowd = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = img_id\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            if not isinstance(img, Image.Image):\n",
    "                img = Image.fromarray(img)\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# path to your own data and coco file\n",
    "import utils\n",
    "train_data_dir = 'data/train'\n",
    "train_coco = 'data/train/_annotations.coco.json'\n",
    "\n",
    "test_data_dir = 'data/test'\n",
    "test_coco = 'data/test/_annotations.coco.json'\n",
    "\n",
    "valid_data_dir = 'data/valid'\n",
    "valid_coco = 'data/valid/_annotations.coco.json'\n",
    "\n",
    "# create own Dataset\n",
    "train_ds = CustomDataset(root=train_data_dir,\n",
    "                          annotation=train_coco,\n",
    "                          transforms=get_transform(train=True)\n",
    "                          )\n",
    "\n",
    "test_ds = CustomDataset(root=test_data_dir,\n",
    "                          annotation=test_coco,\n",
    "                          transforms=get_transform(train=False)\n",
    "                          )\n",
    "\n",
    "valid_ds = CustomDataset(root=valid_data_dir,\n",
    "                          annotation=valid_coco,\n",
    "                          transforms=get_transform(train=False)\n",
    "                          )\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Batch size\n",
    "train_batch_size = 8\n",
    "test_batch_size = 8\n",
    "valid_batch_size = 8\n",
    "\n",
    "# own DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_ds,\n",
    "                                          batch_size=train_batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          collate_fn=utils.collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_ds,\n",
    "                                            batch_size=test_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            collate_fn=utils.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(valid_ds,\n",
    "                                            batch_size=valid_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "# load a pre-trained model for classification and return\n",
    "# only the features\n",
    "backbone = torchvision.models.mobilenet_v3_small(weights=\"DEFAULT\").features\n",
    "# ``FasterRCNN`` needs to know the number of\n",
    "# output channels in a backbone. For mobilenet_v2, it's 1280\n",
    "# so we need to add it here\n",
    "backbone.out_channels = 576\n",
    "\n",
    "# let's make the RPN generate 5 x 3 anchors per spatial\n",
    "# location, with 5 different sizes and 3 different aspect\n",
    "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
    "# map could potentially have different sizes and\n",
    "# aspect ratios\n",
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=((32, 64, 128, 256, 512),),\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
    ")\n",
    "\n",
    "# let's define what are the feature maps that we will\n",
    "# use to perform the region of interest cropping, as well as\n",
    "# the size of the crop after rescaling.\n",
    "# if your backbone returns a Tensor, featmap_names is expected to\n",
    "# be [0]. More generally, the backbone should return an\n",
    "# ``OrderedDict[Tensor]``, and in ``featmap_names`` you can choose which\n",
    "# feature maps to use.\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "    featmap_names=['0'],\n",
    "    output_size=7,\n",
    "    sampling_ratio=2\n",
    ")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# put the pieces together inside a Faster-RCNN model\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=2,\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "def getIoU(bbox, gt):\n",
    "    x1, y1, w1, h1 = bbox\n",
    "    x2, y2, w2, h2 = gt\n",
    "    xA = max(x1, x2)\n",
    "    yA = max(y1, y2)\n",
    "    xB = min(x1+w1, x2+w2)\n",
    "    yB = min(y1+h1, y2+h2)\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = w1 * h1\n",
    "    boxBArea = w2 * h2\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "# mean average precision\n",
    "def get_mAP(pred_boxes, pred_labels, pred_scores, gt_boxes, gt_labels):\n",
    "    # get mAP\n",
    "    pred = [{'boxes': pred_boxes, 'labels': pred_labels, 'scores': pred_scores}]\n",
    "    gt = [{'boxes': gt_boxes, 'labels': gt_labels}]\n",
    "    map_metric = MeanAveragePrecision(iou_thresholds=[0.5], class_metrics=True)\n",
    "    map_metric.update(pred, gt)\n",
    "    mAP = map_metric.compute()\n",
    "    return mAP['map']\n",
    "\n",
    "\n",
    "def validate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    average_IoU = 0\n",
    "\n",
    "    mAP = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            pred = model(images)\n",
    "            pred_boxes = pred[0]['boxes'].cpu()\n",
    "            pred_labels = pred[0]['labels'].cpu()\n",
    "            pred_scores = pred[0]['scores'].cpu()\n",
    "            \n",
    "            gt_boxes = targets[0]['boxes'].cpu()\n",
    "            gt_labels = targets[0]['labels'].cpu()\n",
    "            # get mAP\n",
    "            if(len(pred_boxes) == 0):\n",
    "                continue\n",
    "            mAP += get_mAP(pred_boxes, pred_labels, pred_scores, gt_boxes, gt_labels)\n",
    "            pred_boxes = pred[0]['boxes'].cpu().numpy()\n",
    "            pred_labels = pred[0]['labels'].cpu().numpy()\n",
    "            pred_scores = pred[0]['scores'].cpu().numpy()\n",
    "\n",
    "            gt_boxes = targets[0]['boxes'].cpu().numpy()\n",
    "            gt_labels = targets[0]['labels'].cpu().numpy()\n",
    "\n",
    "            # get IoU\n",
    "            if(len(pred_boxes) == 0):\n",
    "                continue\n",
    "            iou = getIoU(pred_boxes[0], gt_boxes[0])\n",
    "            average_IoU += iou\n",
    "\n",
    "    average_IoU /= len(data_loader)\n",
    "    mAP /= len(data_loader)\n",
    "\n",
    "    return average_IoU, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\engine.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=scaler is not None):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/151]  eta: 0:01:55  lr: 0.000038  loss: 1.6154 (1.6154)  loss_classifier: 0.7832 (0.7832)  loss_box_reg: 0.0230 (0.0230)  loss_objectness: 0.6975 (0.6975)  loss_rpn_box_reg: 0.1117 (0.1117)  time: 0.7617  data: 0.0334  max mem: 3897\n",
      "Epoch: [0]  [ 10/151]  eta: 0:01:05  lr: 0.000371  loss: 1.5194 (1.4516)  loss_classifier: 0.6613 (0.6135)  loss_box_reg: 0.0248 (0.0290)  loss_objectness: 0.6957 (0.6950)  loss_rpn_box_reg: 0.1128 (0.1141)  time: 0.4624  data: 0.0499  max mem: 5944\n",
      "Epoch: [0]  [ 20/151]  eta: 0:00:56  lr: 0.000704  loss: 1.1354 (1.2266)  loss_classifier: 0.2777 (0.3986)  loss_box_reg: 0.0319 (0.0399)  loss_objectness: 0.6857 (0.6840)  loss_rpn_box_reg: 0.0854 (0.1041)  time: 0.4170  data: 0.0472  max mem: 5944\n",
      "Epoch: [0]  [ 30/151]  eta: 0:00:50  lr: 0.001037  loss: 0.9410 (1.1362)  loss_classifier: 0.1536 (0.3312)  loss_box_reg: 0.0600 (0.0491)  loss_objectness: 0.6506 (0.6638)  loss_rpn_box_reg: 0.0688 (0.0921)  time: 0.3962  data: 0.0475  max mem: 5944\n",
      "Epoch: [0]  [ 40/151]  eta: 0:00:42  lr: 0.001370  loss: 0.9497 (1.1223)  loss_classifier: 0.2154 (0.3320)  loss_box_reg: 0.0715 (0.0670)  loss_objectness: 0.5976 (0.6388)  loss_rpn_box_reg: 0.0567 (0.0845)  time: 0.3346  data: 0.0388  max mem: 5944\n",
      "Epoch: [0]  [ 50/151]  eta: 0:00:37  lr: 0.001703  loss: 0.9860 (1.0851)  loss_classifier: 0.2939 (0.3163)  loss_box_reg: 0.1098 (0.0790)  loss_objectness: 0.5229 (0.6092)  loss_rpn_box_reg: 0.0571 (0.0805)  time: 0.2847  data: 0.0347  max mem: 5944\n",
      "Epoch: [0]  [ 60/151]  eta: 0:00:31  lr: 0.002036  loss: 0.8553 (1.0339)  loss_classifier: 0.1871 (0.2909)  loss_box_reg: 0.1237 (0.0875)  loss_objectness: 0.4635 (0.5797)  loss_rpn_box_reg: 0.0571 (0.0758)  time: 0.2738  data: 0.0333  max mem: 5944\n",
      "Epoch: [0]  [ 70/151]  eta: 0:00:27  lr: 0.002369  loss: 0.7249 (0.9869)  loss_classifier: 0.1499 (0.2701)  loss_box_reg: 0.1405 (0.0945)  loss_objectness: 0.3923 (0.5506)  loss_rpn_box_reg: 0.0413 (0.0717)  time: 0.2650  data: 0.0273  max mem: 5944\n",
      "Epoch: [0]  [ 80/151]  eta: 0:00:23  lr: 0.002702  loss: 0.6672 (0.9486)  loss_classifier: 0.1378 (0.2531)  loss_box_reg: 0.1495 (0.1036)  loss_objectness: 0.3357 (0.5226)  loss_rpn_box_reg: 0.0448 (0.0693)  time: 0.3026  data: 0.0469  max mem: 5944\n",
      "Epoch: [0]  [ 90/151]  eta: 0:00:20  lr: 0.003035  loss: 0.5971 (0.9038)  loss_classifier: 0.1153 (0.2371)  loss_box_reg: 0.1554 (0.1071)  loss_objectness: 0.2927 (0.4947)  loss_rpn_box_reg: 0.0353 (0.0649)  time: 0.3062  data: 0.0473  max mem: 5944\n",
      "Epoch: [0]  [100/151]  eta: 0:00:16  lr: 0.003368  loss: 0.5182 (0.8678)  loss_classifier: 0.1066 (0.2254)  loss_box_reg: 0.1505 (0.1128)  loss_objectness: 0.2404 (0.4672)  loss_rpn_box_reg: 0.0338 (0.0624)  time: 0.2980  data: 0.0461  max mem: 5944\n",
      "Epoch: [0]  [110/151]  eta: 0:00:13  lr: 0.003701  loss: 0.4998 (0.8267)  loss_classifier: 0.1043 (0.2133)  loss_box_reg: 0.1349 (0.1132)  loss_objectness: 0.1856 (0.4403)  loss_rpn_box_reg: 0.0358 (0.0599)  time: 0.2955  data: 0.0454  max mem: 5944\n",
      "Epoch: [0]  [120/151]  eta: 0:00:09  lr: 0.004034  loss: 0.3817 (0.7920)  loss_classifier: 0.0873 (0.2038)  loss_box_reg: 0.1103 (0.1138)  loss_objectness: 0.1482 (0.4162)  loss_rpn_box_reg: 0.0358 (0.0582)  time: 0.2818  data: 0.0350  max mem: 5944\n",
      "Epoch: [0]  [130/151]  eta: 0:00:06  lr: 0.004367  loss: 0.3935 (0.7678)  loss_classifier: 0.0985 (0.1973)  loss_box_reg: 0.1150 (0.1161)  loss_objectness: 0.1287 (0.3963)  loss_rpn_box_reg: 0.0369 (0.0582)  time: 0.2786  data: 0.0306  max mem: 5944\n",
      "Epoch: [0]  [140/151]  eta: 0:00:03  lr: 0.004700  loss: 0.4323 (0.7459)  loss_classifier: 0.1255 (0.1924)  loss_box_reg: 0.1487 (0.1195)  loss_objectness: 0.1116 (0.3768)  loss_rpn_box_reg: 0.0346 (0.0572)  time: 0.2564  data: 0.0224  max mem: 5944\n",
      "Epoch: [0]  [150/151]  eta: 0:00:00  lr: 0.005000  loss: 0.4134 (0.7227)  loss_classifier: 0.1177 (0.1871)  loss_box_reg: 0.1507 (0.1201)  loss_objectness: 0.1117 (0.3592)  loss_rpn_box_reg: 0.0346 (0.0563)  time: 0.2544  data: 0.0281  max mem: 5944\n",
      "Epoch: [0] Total time: 0:00:46 (0.3095 s / it)\n",
      "IoU: 0.6005558371543884, mAP: 0.75\n",
      "Epoch: [1]  [  0/151]  eta: 0:00:42  lr: 0.005000  loss: 0.3010 (0.3010)  loss_classifier: 0.0789 (0.0789)  loss_box_reg: 0.0966 (0.0966)  loss_objectness: 0.0826 (0.0826)  loss_rpn_box_reg: 0.0429 (0.0429)  time: 0.2786  data: 0.0120  max mem: 5944\n",
      "Epoch: [1]  [ 10/151]  eta: 0:00:44  lr: 0.005000  loss: 0.3068 (0.3106)  loss_classifier: 0.0778 (0.0750)  loss_box_reg: 0.0877 (0.0841)  loss_objectness: 0.0826 (0.0989)  loss_rpn_box_reg: 0.0499 (0.0526)  time: 0.3145  data: 0.0315  max mem: 5944\n",
      "Epoch: [1]  [ 20/151]  eta: 0:00:42  lr: 0.005000  loss: 0.2625 (0.2712)  loss_classifier: 0.0614 (0.0653)  loss_box_reg: 0.0613 (0.0689)  loss_objectness: 0.0752 (0.0880)  loss_rpn_box_reg: 0.0392 (0.0490)  time: 0.3275  data: 0.0324  max mem: 5944\n",
      "Epoch: [1]  [ 30/151]  eta: 0:00:40  lr: 0.005000  loss: 0.2068 (0.2534)  loss_classifier: 0.0493 (0.0595)  loss_box_reg: 0.0436 (0.0609)  loss_objectness: 0.0741 (0.0858)  loss_rpn_box_reg: 0.0332 (0.0473)  time: 0.3423  data: 0.0320  max mem: 5944\n",
      "Epoch: [1]  [ 40/151]  eta: 0:00:37  lr: 0.005000  loss: 0.2182 (0.2546)  loss_classifier: 0.0499 (0.0600)  loss_box_reg: 0.0464 (0.0609)  loss_objectness: 0.0747 (0.0849)  loss_rpn_box_reg: 0.0431 (0.0488)  time: 0.3562  data: 0.0398  max mem: 5944\n",
      "Epoch: [1]  [ 50/151]  eta: 0:00:34  lr: 0.005000  loss: 0.2153 (0.2453)  loss_classifier: 0.0499 (0.0581)  loss_box_reg: 0.0473 (0.0578)  loss_objectness: 0.0744 (0.0830)  loss_rpn_box_reg: 0.0437 (0.0464)  time: 0.3592  data: 0.0425  max mem: 5944\n",
      "Epoch: [1]  [ 60/151]  eta: 0:00:31  lr: 0.005000  loss: 0.1752 (0.2299)  loss_classifier: 0.0433 (0.0551)  loss_box_reg: 0.0396 (0.0544)  loss_objectness: 0.0596 (0.0775)  loss_rpn_box_reg: 0.0270 (0.0429)  time: 0.3624  data: 0.0340  max mem: 5944\n",
      "Epoch: [1]  [ 70/151]  eta: 0:00:28  lr: 0.005000  loss: 0.1597 (0.2224)  loss_classifier: 0.0377 (0.0528)  loss_box_reg: 0.0336 (0.0519)  loss_objectness: 0.0518 (0.0749)  loss_rpn_box_reg: 0.0276 (0.0427)  time: 0.3847  data: 0.0393  max mem: 5944\n",
      "Epoch: [1]  [ 80/151]  eta: 0:00:25  lr: 0.005000  loss: 0.1663 (0.2168)  loss_classifier: 0.0369 (0.0511)  loss_box_reg: 0.0340 (0.0501)  loss_objectness: 0.0518 (0.0735)  loss_rpn_box_reg: 0.0403 (0.0421)  time: 0.3870  data: 0.0436  max mem: 5944\n",
      "Epoch: [1]  [ 90/151]  eta: 0:00:22  lr: 0.005000  loss: 0.1446 (0.2099)  loss_classifier: 0.0349 (0.0499)  loss_box_reg: 0.0364 (0.0488)  loss_objectness: 0.0458 (0.0708)  loss_rpn_box_reg: 0.0281 (0.0404)  time: 0.3889  data: 0.0437  max mem: 5944\n",
      "Epoch: [1]  [100/151]  eta: 0:00:18  lr: 0.005000  loss: 0.1381 (0.2067)  loss_classifier: 0.0349 (0.0486)  loss_box_reg: 0.0344 (0.0473)  loss_objectness: 0.0466 (0.0701)  loss_rpn_box_reg: 0.0259 (0.0406)  time: 0.3906  data: 0.0407  max mem: 5944\n",
      "Epoch: [1]  [110/151]  eta: 0:00:15  lr: 0.005000  loss: 0.1557 (0.2032)  loss_classifier: 0.0364 (0.0478)  loss_box_reg: 0.0342 (0.0463)  loss_objectness: 0.0511 (0.0684)  loss_rpn_box_reg: 0.0344 (0.0406)  time: 0.3846  data: 0.0361  max mem: 5944\n",
      "Epoch: [1]  [120/151]  eta: 0:00:11  lr: 0.005000  loss: 0.1578 (0.2017)  loss_classifier: 0.0372 (0.0476)  loss_box_reg: 0.0362 (0.0457)  loss_objectness: 0.0480 (0.0672)  loss_rpn_box_reg: 0.0429 (0.0412)  time: 0.3944  data: 0.0429  max mem: 5944\n",
      "Epoch: [1]  [130/151]  eta: 0:00:07  lr: 0.005000  loss: 0.1523 (0.2000)  loss_classifier: 0.0370 (0.0469)  loss_box_reg: 0.0348 (0.0451)  loss_objectness: 0.0462 (0.0656)  loss_rpn_box_reg: 0.0444 (0.0424)  time: 0.4074  data: 0.0479  max mem: 5944\n",
      "Epoch: [1]  [140/151]  eta: 0:00:04  lr: 0.005000  loss: 0.1631 (0.1992)  loss_classifier: 0.0363 (0.0461)  loss_box_reg: 0.0344 (0.0443)  loss_objectness: 0.0493 (0.0648)  loss_rpn_box_reg: 0.0461 (0.0439)  time: 0.4109  data: 0.0476  max mem: 5944\n",
      "Epoch: [1]  [150/151]  eta: 0:00:00  lr: 0.005000  loss: 0.1596 (0.1966)  loss_classifier: 0.0346 (0.0453)  loss_box_reg: 0.0344 (0.0438)  loss_objectness: 0.0506 (0.0639)  loss_rpn_box_reg: 0.0427 (0.0435)  time: 0.3922  data: 0.0431  max mem: 5944\n",
      "Epoch: [1] Total time: 0:00:56 (0.3752 s / it)\n",
      "IoU: 0.8079366087913513, mAP: 0.875117838382721\n",
      "Epoch: [2]  [  0/151]  eta: 0:01:00  lr: 0.005000  loss: 0.2106 (0.2106)  loss_classifier: 0.0610 (0.0610)  loss_box_reg: 0.0572 (0.0572)  loss_objectness: 0.0589 (0.0589)  loss_rpn_box_reg: 0.0336 (0.0336)  time: 0.4016  data: 0.0231  max mem: 5944\n",
      "Epoch: [2]  [ 10/151]  eta: 0:00:55  lr: 0.005000  loss: 0.1655 (0.1688)  loss_classifier: 0.0365 (0.0390)  loss_box_reg: 0.0356 (0.0363)  loss_objectness: 0.0557 (0.0572)  loss_rpn_box_reg: 0.0393 (0.0364)  time: 0.3970  data: 0.0308  max mem: 5944\n",
      "Epoch: [2]  [ 20/151]  eta: 0:00:52  lr: 0.005000  loss: 0.1563 (0.1657)  loss_classifier: 0.0349 (0.0375)  loss_box_reg: 0.0356 (0.0368)  loss_objectness: 0.0461 (0.0515)  loss_rpn_box_reg: 0.0393 (0.0400)  time: 0.4025  data: 0.0400  max mem: 5944\n",
      "Epoch: [2]  [ 30/151]  eta: 0:00:49  lr: 0.005000  loss: 0.1511 (0.1606)  loss_classifier: 0.0325 (0.0357)  loss_box_reg: 0.0356 (0.0356)  loss_objectness: 0.0410 (0.0482)  loss_rpn_box_reg: 0.0386 (0.0411)  time: 0.4121  data: 0.0516  max mem: 5944\n",
      "Epoch: [2]  [ 40/151]  eta: 0:00:45  lr: 0.005000  loss: 0.1429 (0.1585)  loss_classifier: 0.0314 (0.0352)  loss_box_reg: 0.0319 (0.0352)  loss_objectness: 0.0391 (0.0473)  loss_rpn_box_reg: 0.0337 (0.0408)  time: 0.4145  data: 0.0505  max mem: 5944\n",
      "Epoch: [2]  [ 50/151]  eta: 0:00:41  lr: 0.005000  loss: 0.1361 (0.1541)  loss_classifier: 0.0317 (0.0346)  loss_box_reg: 0.0313 (0.0348)  loss_objectness: 0.0373 (0.0449)  loss_rpn_box_reg: 0.0369 (0.0397)  time: 0.4197  data: 0.0558  max mem: 5944\n",
      "Epoch: [2]  [ 60/151]  eta: 0:00:37  lr: 0.005000  loss: 0.1332 (0.1507)  loss_classifier: 0.0310 (0.0347)  loss_box_reg: 0.0311 (0.0344)  loss_objectness: 0.0360 (0.0443)  loss_rpn_box_reg: 0.0296 (0.0373)  time: 0.4087  data: 0.0510  max mem: 5944\n",
      "Epoch: [2]  [ 70/151]  eta: 0:00:32  lr: 0.005000  loss: 0.1503 (0.1527)  loss_classifier: 0.0335 (0.0346)  loss_box_reg: 0.0329 (0.0342)  loss_objectness: 0.0469 (0.0457)  loss_rpn_box_reg: 0.0303 (0.0382)  time: 0.3896  data: 0.0357  max mem: 5944\n",
      "Epoch: [2]  [ 80/151]  eta: 0:00:28  lr: 0.005000  loss: 0.1349 (0.1494)  loss_classifier: 0.0320 (0.0341)  loss_box_reg: 0.0331 (0.0339)  loss_objectness: 0.0391 (0.0446)  loss_rpn_box_reg: 0.0318 (0.0369)  time: 0.4059  data: 0.0375  max mem: 5944\n",
      "Epoch: [2]  [ 90/151]  eta: 0:00:25  lr: 0.005000  loss: 0.1234 (0.1489)  loss_classifier: 0.0306 (0.0343)  loss_box_reg: 0.0337 (0.0343)  loss_objectness: 0.0359 (0.0448)  loss_rpn_box_reg: 0.0215 (0.0356)  time: 0.4332  data: 0.0524  max mem: 5944\n",
      "Epoch: [2]  [100/151]  eta: 0:00:20  lr: 0.005000  loss: 0.1271 (0.1471)  loss_classifier: 0.0320 (0.0341)  loss_box_reg: 0.0353 (0.0343)  loss_objectness: 0.0334 (0.0439)  loss_rpn_box_reg: 0.0247 (0.0349)  time: 0.4167  data: 0.0510  max mem: 5944\n",
      "Epoch: [2]  [110/151]  eta: 0:00:16  lr: 0.005000  loss: 0.1203 (0.1461)  loss_classifier: 0.0291 (0.0335)  loss_box_reg: 0.0323 (0.0340)  loss_objectness: 0.0302 (0.0439)  loss_rpn_box_reg: 0.0301 (0.0347)  time: 0.4076  data: 0.0453  max mem: 5944\n",
      "Epoch: [2]  [120/151]  eta: 0:00:12  lr: 0.005000  loss: 0.1396 (0.1467)  loss_classifier: 0.0298 (0.0335)  loss_box_reg: 0.0321 (0.0342)  loss_objectness: 0.0347 (0.0438)  loss_rpn_box_reg: 0.0314 (0.0352)  time: 0.4201  data: 0.0479  max mem: 5944\n",
      "Epoch: [2]  [130/151]  eta: 0:00:08  lr: 0.005000  loss: 0.1341 (0.1463)  loss_classifier: 0.0289 (0.0331)  loss_box_reg: 0.0316 (0.0338)  loss_objectness: 0.0357 (0.0442)  loss_rpn_box_reg: 0.0316 (0.0352)  time: 0.4090  data: 0.0369  max mem: 5944\n",
      "Epoch: [2]  [140/151]  eta: 0:00:04  lr: 0.005000  loss: 0.1194 (0.1459)  loss_classifier: 0.0273 (0.0331)  loss_box_reg: 0.0302 (0.0340)  loss_objectness: 0.0347 (0.0439)  loss_rpn_box_reg: 0.0299 (0.0350)  time: 0.3896  data: 0.0296  max mem: 5944\n",
      "Epoch: [2]  [150/151]  eta: 0:00:00  lr: 0.005000  loss: 0.1337 (0.1454)  loss_classifier: 0.0284 (0.0328)  loss_box_reg: 0.0329 (0.0339)  loss_objectness: 0.0353 (0.0435)  loss_rpn_box_reg: 0.0332 (0.0351)  time: 0.3775  data: 0.0337  max mem: 5944\n",
      "Epoch: [2] Total time: 0:01:01 (0.4063 s / it)\n",
      "IoU: 0.7948288917541504, mAP: 0.90412837266922\n",
      "Epoch: [3]  [  0/151]  eta: 0:00:57  lr: 0.000500  loss: 0.1295 (0.1295)  loss_classifier: 0.0278 (0.0278)  loss_box_reg: 0.0376 (0.0376)  loss_objectness: 0.0330 (0.0330)  loss_rpn_box_reg: 0.0311 (0.0311)  time: 0.3831  data: 0.0246  max mem: 5944\n",
      "Epoch: [3]  [ 10/151]  eta: 0:00:55  lr: 0.000500  loss: 0.1161 (0.1319)  loss_classifier: 0.0272 (0.0300)  loss_box_reg: 0.0333 (0.0365)  loss_objectness: 0.0279 (0.0362)  loss_rpn_box_reg: 0.0235 (0.0293)  time: 0.3924  data: 0.0282  max mem: 5944\n",
      "Epoch: [3]  [ 20/151]  eta: 0:00:52  lr: 0.000500  loss: 0.1101 (0.1239)  loss_classifier: 0.0272 (0.0310)  loss_box_reg: 0.0304 (0.0335)  loss_objectness: 0.0301 (0.0339)  loss_rpn_box_reg: 0.0216 (0.0255)  time: 0.4003  data: 0.0367  max mem: 5944\n",
      "Epoch: [3]  [ 30/151]  eta: 0:00:48  lr: 0.000500  loss: 0.1094 (0.1249)  loss_classifier: 0.0270 (0.0304)  loss_box_reg: 0.0314 (0.0335)  loss_objectness: 0.0318 (0.0337)  loss_rpn_box_reg: 0.0225 (0.0273)  time: 0.4067  data: 0.0421  max mem: 5944\n",
      "Epoch: [3]  [ 40/151]  eta: 0:00:44  lr: 0.000500  loss: 0.1163 (0.1243)  loss_classifier: 0.0258 (0.0302)  loss_box_reg: 0.0340 (0.0333)  loss_objectness: 0.0297 (0.0335)  loss_rpn_box_reg: 0.0255 (0.0273)  time: 0.4090  data: 0.0456  max mem: 5944\n",
      "Epoch: [3]  [ 50/151]  eta: 0:00:41  lr: 0.000500  loss: 0.1203 (0.1251)  loss_classifier: 0.0258 (0.0299)  loss_box_reg: 0.0316 (0.0331)  loss_objectness: 0.0325 (0.0343)  loss_rpn_box_reg: 0.0255 (0.0279)  time: 0.4262  data: 0.0555  max mem: 5944\n",
      "Epoch: [3]  [ 60/151]  eta: 0:00:37  lr: 0.000500  loss: 0.1161 (0.1241)  loss_classifier: 0.0273 (0.0296)  loss_box_reg: 0.0312 (0.0325)  loss_objectness: 0.0325 (0.0342)  loss_rpn_box_reg: 0.0250 (0.0278)  time: 0.4179  data: 0.0486  max mem: 5944\n",
      "Epoch: [3]  [ 70/151]  eta: 0:00:32  lr: 0.000500  loss: 0.1194 (0.1250)  loss_classifier: 0.0276 (0.0304)  loss_box_reg: 0.0322 (0.0330)  loss_objectness: 0.0356 (0.0347)  loss_rpn_box_reg: 0.0243 (0.0269)  time: 0.3922  data: 0.0370  max mem: 5944\n",
      "Epoch: [3]  [ 80/151]  eta: 0:00:28  lr: 0.000500  loss: 0.1271 (0.1241)  loss_classifier: 0.0297 (0.0304)  loss_box_reg: 0.0347 (0.0329)  loss_objectness: 0.0359 (0.0344)  loss_rpn_box_reg: 0.0222 (0.0263)  time: 0.4039  data: 0.0428  max mem: 5944\n",
      "Epoch: [3]  [ 90/151]  eta: 0:00:24  lr: 0.000500  loss: 0.1154 (0.1235)  loss_classifier: 0.0292 (0.0303)  loss_box_reg: 0.0317 (0.0326)  loss_objectness: 0.0342 (0.0344)  loss_rpn_box_reg: 0.0211 (0.0262)  time: 0.4049  data: 0.0439  max mem: 5944\n",
      "Epoch: [3]  [100/151]  eta: 0:00:20  lr: 0.000500  loss: 0.1275 (0.1247)  loss_classifier: 0.0286 (0.0301)  loss_box_reg: 0.0308 (0.0324)  loss_objectness: 0.0354 (0.0349)  loss_rpn_box_reg: 0.0225 (0.0272)  time: 0.3985  data: 0.0370  max mem: 5944\n",
      "Epoch: [3]  [110/151]  eta: 0:00:16  lr: 0.000500  loss: 0.1082 (0.1230)  loss_classifier: 0.0258 (0.0299)  loss_box_reg: 0.0305 (0.0321)  loss_objectness: 0.0297 (0.0344)  loss_rpn_box_reg: 0.0225 (0.0266)  time: 0.4178  data: 0.0473  max mem: 5944\n",
      "Epoch: [3]  [120/151]  eta: 0:00:12  lr: 0.000500  loss: 0.1090 (0.1231)  loss_classifier: 0.0292 (0.0298)  loss_box_reg: 0.0314 (0.0322)  loss_objectness: 0.0277 (0.0343)  loss_rpn_box_reg: 0.0215 (0.0268)  time: 0.4253  data: 0.0556  max mem: 5944\n",
      "Epoch: [3]  [130/151]  eta: 0:00:08  lr: 0.000500  loss: 0.1189 (0.1235)  loss_classifier: 0.0289 (0.0298)  loss_box_reg: 0.0316 (0.0321)  loss_objectness: 0.0313 (0.0347)  loss_rpn_box_reg: 0.0220 (0.0270)  time: 0.4078  data: 0.0435  max mem: 5944\n",
      "Epoch: [3]  [140/151]  eta: 0:00:04  lr: 0.000500  loss: 0.1206 (0.1232)  loss_classifier: 0.0277 (0.0298)  loss_box_reg: 0.0316 (0.0321)  loss_objectness: 0.0302 (0.0345)  loss_rpn_box_reg: 0.0198 (0.0268)  time: 0.4044  data: 0.0414  max mem: 5944\n",
      "Epoch: [3]  [150/151]  eta: 0:00:00  lr: 0.000500  loss: 0.1156 (0.1239)  loss_classifier: 0.0285 (0.0297)  loss_box_reg: 0.0313 (0.0321)  loss_objectness: 0.0305 (0.0350)  loss_rpn_box_reg: 0.0267 (0.0271)  time: 0.4092  data: 0.0480  max mem: 5944\n",
      "Epoch: [3] Total time: 0:01:01 (0.4081 s / it)\n",
      "IoU: 0.847598135471344, mAP: 0.9257131218910217\n",
      "Epoch: [4]  [  0/151]  eta: 0:01:01  lr: 0.000500  loss: 0.0944 (0.0944)  loss_classifier: 0.0257 (0.0257)  loss_box_reg: 0.0275 (0.0275)  loss_objectness: 0.0186 (0.0186)  loss_rpn_box_reg: 0.0226 (0.0226)  time: 0.4060  data: 0.0325  max mem: 5944\n",
      "Epoch: [4]  [ 10/151]  eta: 0:01:02  lr: 0.000500  loss: 0.1074 (0.1314)  loss_classifier: 0.0257 (0.0284)  loss_box_reg: 0.0286 (0.0320)  loss_objectness: 0.0290 (0.0404)  loss_rpn_box_reg: 0.0244 (0.0305)  time: 0.4434  data: 0.0620  max mem: 5944\n",
      "Epoch: [4]  [ 20/151]  eta: 0:00:56  lr: 0.000500  loss: 0.1074 (0.1275)  loss_classifier: 0.0252 (0.0285)  loss_box_reg: 0.0281 (0.0302)  loss_objectness: 0.0336 (0.0410)  loss_rpn_box_reg: 0.0244 (0.0279)  time: 0.4342  data: 0.0554  max mem: 5944\n",
      "Epoch: [4]  [ 30/151]  eta: 0:00:50  lr: 0.000500  loss: 0.1103 (0.1258)  loss_classifier: 0.0262 (0.0281)  loss_box_reg: 0.0281 (0.0301)  loss_objectness: 0.0336 (0.0398)  loss_rpn_box_reg: 0.0211 (0.0279)  time: 0.4052  data: 0.0403  max mem: 5944\n",
      "Epoch: [4]  [ 40/151]  eta: 0:00:46  lr: 0.000500  loss: 0.1108 (0.1215)  loss_classifier: 0.0263 (0.0279)  loss_box_reg: 0.0294 (0.0299)  loss_objectness: 0.0288 (0.0370)  loss_rpn_box_reg: 0.0200 (0.0267)  time: 0.4050  data: 0.0401  max mem: 5967\n",
      "Epoch: [4]  [ 50/151]  eta: 0:00:42  lr: 0.000500  loss: 0.1146 (0.1255)  loss_classifier: 0.0283 (0.0286)  loss_box_reg: 0.0294 (0.0305)  loss_objectness: 0.0346 (0.0377)  loss_rpn_box_reg: 0.0271 (0.0287)  time: 0.4139  data: 0.0419  max mem: 5967\n",
      "Epoch: [4]  [ 60/151]  eta: 0:00:37  lr: 0.000500  loss: 0.1305 (0.1259)  loss_classifier: 0.0299 (0.0293)  loss_box_reg: 0.0292 (0.0312)  loss_objectness: 0.0368 (0.0373)  loss_rpn_box_reg: 0.0249 (0.0282)  time: 0.4103  data: 0.0399  max mem: 5967\n",
      "Epoch: [4]  [ 70/151]  eta: 0:00:33  lr: 0.000500  loss: 0.1278 (0.1260)  loss_classifier: 0.0319 (0.0296)  loss_box_reg: 0.0282 (0.0310)  loss_objectness: 0.0355 (0.0377)  loss_rpn_box_reg: 0.0212 (0.0277)  time: 0.4152  data: 0.0446  max mem: 5967\n",
      "Epoch: [4]  [ 80/151]  eta: 0:00:29  lr: 0.000500  loss: 0.1144 (0.1254)  loss_classifier: 0.0296 (0.0295)  loss_box_reg: 0.0295 (0.0312)  loss_objectness: 0.0355 (0.0370)  loss_rpn_box_reg: 0.0212 (0.0276)  time: 0.4225  data: 0.0539  max mem: 5967\n",
      "Epoch: [4]  [ 90/151]  eta: 0:00:25  lr: 0.000500  loss: 0.1190 (0.1252)  loss_classifier: 0.0280 (0.0294)  loss_box_reg: 0.0302 (0.0313)  loss_objectness: 0.0334 (0.0368)  loss_rpn_box_reg: 0.0270 (0.0278)  time: 0.4205  data: 0.0488  max mem: 5967\n",
      "Epoch: [4]  [100/151]  eta: 0:00:21  lr: 0.000500  loss: 0.1163 (0.1232)  loss_classifier: 0.0271 (0.0294)  loss_box_reg: 0.0302 (0.0311)  loss_objectness: 0.0293 (0.0358)  loss_rpn_box_reg: 0.0214 (0.0269)  time: 0.4177  data: 0.0453  max mem: 5967\n",
      "Epoch: [4]  [110/151]  eta: 0:00:17  lr: 0.000500  loss: 0.1032 (0.1217)  loss_classifier: 0.0264 (0.0290)  loss_box_reg: 0.0288 (0.0309)  loss_objectness: 0.0257 (0.0351)  loss_rpn_box_reg: 0.0211 (0.0266)  time: 0.4190  data: 0.0518  max mem: 5967\n",
      "Epoch: [4]  [120/151]  eta: 0:00:12  lr: 0.000500  loss: 0.1076 (0.1211)  loss_classifier: 0.0238 (0.0289)  loss_box_reg: 0.0289 (0.0311)  loss_objectness: 0.0257 (0.0344)  loss_rpn_box_reg: 0.0246 (0.0266)  time: 0.4063  data: 0.0422  max mem: 5967\n",
      "Epoch: [4]  [130/151]  eta: 0:00:08  lr: 0.000500  loss: 0.1021 (0.1199)  loss_classifier: 0.0238 (0.0288)  loss_box_reg: 0.0278 (0.0310)  loss_objectness: 0.0251 (0.0338)  loss_rpn_box_reg: 0.0246 (0.0264)  time: 0.4136  data: 0.0475  max mem: 5967\n",
      "Epoch: [4]  [140/151]  eta: 0:00:04  lr: 0.000500  loss: 0.0964 (0.1188)  loss_classifier: 0.0240 (0.0285)  loss_box_reg: 0.0276 (0.0308)  loss_objectness: 0.0281 (0.0334)  loss_rpn_box_reg: 0.0206 (0.0260)  time: 0.4195  data: 0.0503  max mem: 5967\n",
      "Epoch: [4]  [150/151]  eta: 0:00:00  lr: 0.000500  loss: 0.0964 (0.1181)  loss_classifier: 0.0257 (0.0285)  loss_box_reg: 0.0307 (0.0310)  loss_objectness: 0.0266 (0.0329)  loss_rpn_box_reg: 0.0195 (0.0257)  time: 0.3971  data: 0.0373  max mem: 5967\n",
      "Epoch: [4] Total time: 0:01:02 (0.4144 s / it)\n",
      "IoU: 0.8407670855522156, mAP: 0.9301332235336304\n",
      "Epoch: [5]  [  0/151]  eta: 0:01:04  lr: 0.000500  loss: 0.1166 (0.1166)  loss_classifier: 0.0227 (0.0227)  loss_box_reg: 0.0318 (0.0318)  loss_objectness: 0.0293 (0.0293)  loss_rpn_box_reg: 0.0328 (0.0328)  time: 0.4303  data: 0.0659  max mem: 5967\n",
      "Epoch: [5]  [ 10/151]  eta: 0:00:57  lr: 0.000500  loss: 0.1032 (0.1138)  loss_classifier: 0.0265 (0.0283)  loss_box_reg: 0.0300 (0.0294)  loss_objectness: 0.0285 (0.0304)  loss_rpn_box_reg: 0.0255 (0.0257)  time: 0.4111  data: 0.0401  max mem: 5967\n",
      "Epoch: [5]  [ 20/151]  eta: 0:00:55  lr: 0.000500  loss: 0.1118 (0.1191)  loss_classifier: 0.0279 (0.0293)  loss_box_reg: 0.0298 (0.0305)  loss_objectness: 0.0283 (0.0326)  loss_rpn_box_reg: 0.0236 (0.0267)  time: 0.4210  data: 0.0497  max mem: 5967\n",
      "Epoch: [5]  [ 30/151]  eta: 0:00:50  lr: 0.000500  loss: 0.1118 (0.1168)  loss_classifier: 0.0267 (0.0285)  loss_box_reg: 0.0293 (0.0296)  loss_objectness: 0.0283 (0.0330)  loss_rpn_box_reg: 0.0219 (0.0257)  time: 0.4203  data: 0.0538  max mem: 5967\n",
      "Epoch: [5]  [ 40/151]  eta: 0:00:45  lr: 0.000500  loss: 0.1007 (0.1209)  loss_classifier: 0.0261 (0.0282)  loss_box_reg: 0.0269 (0.0299)  loss_objectness: 0.0280 (0.0360)  loss_rpn_box_reg: 0.0188 (0.0268)  time: 0.3968  data: 0.0412  max mem: 5967\n",
      "Epoch: [5]  [ 50/151]  eta: 0:00:41  lr: 0.000500  loss: 0.0925 (0.1175)  loss_classifier: 0.0263 (0.0281)  loss_box_reg: 0.0289 (0.0301)  loss_objectness: 0.0275 (0.0345)  loss_rpn_box_reg: 0.0172 (0.0248)  time: 0.3956  data: 0.0378  max mem: 5967\n",
      "Epoch: [5]  [ 60/151]  eta: 0:00:37  lr: 0.000500  loss: 0.1037 (0.1191)  loss_classifier: 0.0255 (0.0280)  loss_box_reg: 0.0290 (0.0301)  loss_objectness: 0.0292 (0.0353)  loss_rpn_box_reg: 0.0167 (0.0257)  time: 0.4032  data: 0.0393  max mem: 5967\n",
      "Epoch: [5]  [ 70/151]  eta: 0:00:32  lr: 0.000500  loss: 0.1167 (0.1196)  loss_classifier: 0.0255 (0.0277)  loss_box_reg: 0.0278 (0.0299)  loss_objectness: 0.0325 (0.0356)  loss_rpn_box_reg: 0.0298 (0.0263)  time: 0.4040  data: 0.0457  max mem: 5967\n",
      "Epoch: [5]  [ 80/151]  eta: 0:00:29  lr: 0.000500  loss: 0.1057 (0.1186)  loss_classifier: 0.0240 (0.0282)  loss_box_reg: 0.0266 (0.0299)  loss_objectness: 0.0298 (0.0348)  loss_rpn_box_reg: 0.0224 (0.0256)  time: 0.4267  data: 0.0560  max mem: 5967\n",
      "Epoch: [5]  [ 90/151]  eta: 0:00:25  lr: 0.000500  loss: 0.1012 (0.1174)  loss_classifier: 0.0240 (0.0280)  loss_box_reg: 0.0263 (0.0295)  loss_objectness: 0.0284 (0.0347)  loss_rpn_box_reg: 0.0206 (0.0253)  time: 0.4382  data: 0.0602  max mem: 5967\n",
      "Epoch: [5]  [100/151]  eta: 0:00:21  lr: 0.000500  loss: 0.0926 (0.1153)  loss_classifier: 0.0226 (0.0275)  loss_box_reg: 0.0261 (0.0293)  loss_objectness: 0.0250 (0.0337)  loss_rpn_box_reg: 0.0172 (0.0247)  time: 0.4140  data: 0.0497  max mem: 5967\n",
      "Epoch: [5]  [110/151]  eta: 0:00:16  lr: 0.000500  loss: 0.1000 (0.1169)  loss_classifier: 0.0242 (0.0277)  loss_box_reg: 0.0288 (0.0297)  loss_objectness: 0.0271 (0.0342)  loss_rpn_box_reg: 0.0209 (0.0253)  time: 0.4010  data: 0.0368  max mem: 5967\n",
      "Epoch: [5]  [120/151]  eta: 0:00:12  lr: 0.000500  loss: 0.1061 (0.1158)  loss_classifier: 0.0242 (0.0276)  loss_box_reg: 0.0277 (0.0295)  loss_objectness: 0.0275 (0.0338)  loss_rpn_box_reg: 0.0211 (0.0249)  time: 0.4054  data: 0.0402  max mem: 5967\n",
      "Epoch: [5]  [130/151]  eta: 0:00:08  lr: 0.000500  loss: 0.0989 (0.1156)  loss_classifier: 0.0237 (0.0275)  loss_box_reg: 0.0270 (0.0296)  loss_objectness: 0.0261 (0.0335)  loss_rpn_box_reg: 0.0201 (0.0251)  time: 0.4077  data: 0.0447  max mem: 5967\n",
      "Epoch: [5]  [140/151]  eta: 0:00:04  lr: 0.000500  loss: 0.1037 (0.1155)  loss_classifier: 0.0250 (0.0275)  loss_box_reg: 0.0287 (0.0297)  loss_objectness: 0.0276 (0.0332)  loss_rpn_box_reg: 0.0187 (0.0251)  time: 0.4014  data: 0.0361  max mem: 5967\n",
      "Epoch: [5]  [150/151]  eta: 0:00:00  lr: 0.000500  loss: 0.1142 (0.1160)  loss_classifier: 0.0266 (0.0276)  loss_box_reg: 0.0332 (0.0299)  loss_objectness: 0.0255 (0.0331)  loss_rpn_box_reg: 0.0190 (0.0255)  time: 0.3981  data: 0.0385  max mem: 5967\n",
      "Epoch: [5] Total time: 0:01:01 (0.4095 s / it)\n",
      "IoU: 0.8546541333198547, mAP: 0.9212046265602112\n",
      "Epoch: [6]  [  0/151]  eta: 0:00:58  lr: 0.000050  loss: 0.1205 (0.1205)  loss_classifier: 0.0296 (0.0296)  loss_box_reg: 0.0286 (0.0286)  loss_objectness: 0.0319 (0.0319)  loss_rpn_box_reg: 0.0303 (0.0303)  time: 0.3889  data: 0.0260  max mem: 5967\n",
      "Epoch: [6]  [ 10/151]  eta: 0:00:57  lr: 0.000050  loss: 0.1040 (0.1042)  loss_classifier: 0.0257 (0.0254)  loss_box_reg: 0.0290 (0.0296)  loss_objectness: 0.0250 (0.0264)  loss_rpn_box_reg: 0.0206 (0.0229)  time: 0.4052  data: 0.0437  max mem: 5967\n",
      "Epoch: [6]  [ 20/151]  eta: 0:00:52  lr: 0.000050  loss: 0.1040 (0.1120)  loss_classifier: 0.0248 (0.0255)  loss_box_reg: 0.0290 (0.0296)  loss_objectness: 0.0267 (0.0307)  loss_rpn_box_reg: 0.0242 (0.0262)  time: 0.4043  data: 0.0401  max mem: 5967\n",
      "Epoch: [6]  [ 30/151]  eta: 0:00:49  lr: 0.000050  loss: 0.1203 (0.1137)  loss_classifier: 0.0273 (0.0275)  loss_box_reg: 0.0271 (0.0295)  loss_objectness: 0.0294 (0.0312)  loss_rpn_box_reg: 0.0273 (0.0255)  time: 0.4172  data: 0.0448  max mem: 5967\n",
      "Epoch: [6]  [ 40/151]  eta: 0:00:45  lr: 0.000050  loss: 0.1143 (0.1162)  loss_classifier: 0.0284 (0.0282)  loss_box_reg: 0.0282 (0.0301)  loss_objectness: 0.0291 (0.0320)  loss_rpn_box_reg: 0.0273 (0.0260)  time: 0.4215  data: 0.0496  max mem: 5967\n",
      "Epoch: [6]  [ 50/151]  eta: 0:00:41  lr: 0.000050  loss: 0.1062 (0.1137)  loss_classifier: 0.0249 (0.0276)  loss_box_reg: 0.0278 (0.0294)  loss_objectness: 0.0278 (0.0314)  loss_rpn_box_reg: 0.0228 (0.0253)  time: 0.4075  data: 0.0403  max mem: 5967\n",
      "Epoch: [6]  [ 60/151]  eta: 0:00:36  lr: 0.000050  loss: 0.0942 (0.1159)  loss_classifier: 0.0242 (0.0278)  loss_box_reg: 0.0269 (0.0297)  loss_objectness: 0.0249 (0.0324)  loss_rpn_box_reg: 0.0182 (0.0259)  time: 0.3933  data: 0.0340  max mem: 5967\n",
      "Epoch: [6]  [ 70/151]  eta: 0:00:32  lr: 0.000050  loss: 0.1016 (0.1155)  loss_classifier: 0.0237 (0.0273)  loss_box_reg: 0.0297 (0.0298)  loss_objectness: 0.0271 (0.0324)  loss_rpn_box_reg: 0.0204 (0.0260)  time: 0.3974  data: 0.0424  max mem: 5967\n",
      "Epoch: [6]  [ 80/151]  eta: 0:00:29  lr: 0.000050  loss: 0.0992 (0.1169)  loss_classifier: 0.0237 (0.0281)  loss_box_reg: 0.0295 (0.0304)  loss_objectness: 0.0269 (0.0325)  loss_rpn_box_reg: 0.0227 (0.0258)  time: 0.4409  data: 0.0695  max mem: 5977\n",
      "Epoch: [6]  [ 90/151]  eta: 0:00:25  lr: 0.000050  loss: 0.1022 (0.1173)  loss_classifier: 0.0263 (0.0282)  loss_box_reg: 0.0298 (0.0305)  loss_objectness: 0.0269 (0.0325)  loss_rpn_box_reg: 0.0252 (0.0261)  time: 0.4367  data: 0.0670  max mem: 5977\n",
      "Epoch: [6]  [100/151]  eta: 0:00:21  lr: 0.000050  loss: 0.1044 (0.1163)  loss_classifier: 0.0263 (0.0283)  loss_box_reg: 0.0298 (0.0305)  loss_objectness: 0.0272 (0.0321)  loss_rpn_box_reg: 0.0219 (0.0254)  time: 0.4074  data: 0.0494  max mem: 5977\n",
      "Epoch: [6]  [110/151]  eta: 0:00:16  lr: 0.000050  loss: 0.1014 (0.1151)  loss_classifier: 0.0254 (0.0282)  loss_box_reg: 0.0288 (0.0305)  loss_objectness: 0.0242 (0.0314)  loss_rpn_box_reg: 0.0170 (0.0250)  time: 0.4131  data: 0.0475  max mem: 5977\n",
      "Epoch: [6]  [120/151]  eta: 0:00:12  lr: 0.000050  loss: 0.0981 (0.1145)  loss_classifier: 0.0239 (0.0280)  loss_box_reg: 0.0284 (0.0304)  loss_objectness: 0.0255 (0.0313)  loss_rpn_box_reg: 0.0197 (0.0249)  time: 0.4025  data: 0.0362  max mem: 5977\n",
      "Epoch: [6]  [130/151]  eta: 0:00:08  lr: 0.000050  loss: 0.1082 (0.1145)  loss_classifier: 0.0246 (0.0278)  loss_box_reg: 0.0294 (0.0302)  loss_objectness: 0.0277 (0.0318)  loss_rpn_box_reg: 0.0217 (0.0249)  time: 0.3984  data: 0.0365  max mem: 5977\n",
      "Epoch: [6]  [140/151]  eta: 0:00:04  lr: 0.000050  loss: 0.1105 (0.1150)  loss_classifier: 0.0269 (0.0278)  loss_box_reg: 0.0294 (0.0302)  loss_objectness: 0.0273 (0.0319)  loss_rpn_box_reg: 0.0217 (0.0252)  time: 0.4116  data: 0.0449  max mem: 5977\n",
      "Epoch: [6]  [150/151]  eta: 0:00:00  lr: 0.000050  loss: 0.1021 (0.1139)  loss_classifier: 0.0269 (0.0276)  loss_box_reg: 0.0276 (0.0302)  loss_objectness: 0.0260 (0.0313)  loss_rpn_box_reg: 0.0207 (0.0247)  time: 0.3897  data: 0.0372  max mem: 5977\n",
      "Epoch: [6] Total time: 0:01:01 (0.4084 s / it)\n",
      "IoU: 0.8501996397972107, mAP: 0.9301332235336304\n",
      "Epoch: [7]  [  0/151]  eta: 0:01:20  lr: 0.000050  loss: 0.1106 (0.1106)  loss_classifier: 0.0237 (0.0237)  loss_box_reg: 0.0282 (0.0282)  loss_objectness: 0.0300 (0.0300)  loss_rpn_box_reg: 0.0286 (0.0286)  time: 0.5313  data: 0.1627  max mem: 5977\n",
      "Epoch: [7]  [ 10/151]  eta: 0:00:58  lr: 0.000050  loss: 0.1106 (0.1100)  loss_classifier: 0.0248 (0.0260)  loss_box_reg: 0.0282 (0.0266)  loss_objectness: 0.0300 (0.0333)  loss_rpn_box_reg: 0.0209 (0.0241)  time: 0.4152  data: 0.0573  max mem: 5977\n",
      "Epoch: [7]  [ 20/151]  eta: 0:00:54  lr: 0.000050  loss: 0.1166 (0.1134)  loss_classifier: 0.0258 (0.0272)  loss_box_reg: 0.0263 (0.0275)  loss_objectness: 0.0322 (0.0347)  loss_rpn_box_reg: 0.0193 (0.0239)  time: 0.4066  data: 0.0507  max mem: 5977\n",
      "Epoch: [7]  [ 30/151]  eta: 0:00:50  lr: 0.000050  loss: 0.1106 (0.1099)  loss_classifier: 0.0255 (0.0267)  loss_box_reg: 0.0277 (0.0281)  loss_objectness: 0.0321 (0.0319)  loss_rpn_box_reg: 0.0184 (0.0232)  time: 0.4128  data: 0.0548  max mem: 5977\n",
      "Epoch: [7]  [ 40/151]  eta: 0:00:46  lr: 0.000050  loss: 0.0901 (0.1106)  loss_classifier: 0.0250 (0.0271)  loss_box_reg: 0.0277 (0.0283)  loss_objectness: 0.0243 (0.0326)  loss_rpn_box_reg: 0.0149 (0.0226)  time: 0.4191  data: 0.0509  max mem: 5977\n",
      "Epoch: [7]  [ 50/151]  eta: 0:00:41  lr: 0.000050  loss: 0.0910 (0.1106)  loss_classifier: 0.0255 (0.0273)  loss_box_reg: 0.0260 (0.0287)  loss_objectness: 0.0244 (0.0321)  loss_rpn_box_reg: 0.0183 (0.0225)  time: 0.4151  data: 0.0426  max mem: 5977\n",
      "Epoch: [7]  [ 60/151]  eta: 0:00:37  lr: 0.000050  loss: 0.1061 (0.1111)  loss_classifier: 0.0255 (0.0268)  loss_box_reg: 0.0286 (0.0288)  loss_objectness: 0.0280 (0.0318)  loss_rpn_box_reg: 0.0215 (0.0237)  time: 0.4055  data: 0.0382  max mem: 5977\n",
      "Epoch: [7]  [ 70/151]  eta: 0:00:33  lr: 0.000050  loss: 0.1001 (0.1110)  loss_classifier: 0.0239 (0.0267)  loss_box_reg: 0.0286 (0.0292)  loss_objectness: 0.0244 (0.0313)  loss_rpn_box_reg: 0.0239 (0.0239)  time: 0.4176  data: 0.0448  max mem: 5977\n",
      "Epoch: [7]  [ 80/151]  eta: 0:00:29  lr: 0.000050  loss: 0.0964 (0.1112)  loss_classifier: 0.0251 (0.0266)  loss_box_reg: 0.0276 (0.0289)  loss_objectness: 0.0222 (0.0319)  loss_rpn_box_reg: 0.0170 (0.0238)  time: 0.4251  data: 0.0505  max mem: 5977\n",
      "Epoch: [7]  [ 90/151]  eta: 0:00:25  lr: 0.000050  loss: 0.1014 (0.1118)  loss_classifier: 0.0262 (0.0268)  loss_box_reg: 0.0276 (0.0289)  loss_objectness: 0.0310 (0.0318)  loss_rpn_box_reg: 0.0187 (0.0243)  time: 0.4100  data: 0.0391  max mem: 5977\n",
      "Epoch: [7]  [100/151]  eta: 0:00:21  lr: 0.000050  loss: 0.1051 (0.1114)  loss_classifier: 0.0262 (0.0267)  loss_box_reg: 0.0280 (0.0290)  loss_objectness: 0.0284 (0.0313)  loss_rpn_box_reg: 0.0240 (0.0244)  time: 0.4191  data: 0.0452  max mem: 5977\n",
      "Epoch: [7]  [110/151]  eta: 0:00:17  lr: 0.000050  loss: 0.0989 (0.1111)  loss_classifier: 0.0261 (0.0267)  loss_box_reg: 0.0274 (0.0289)  loss_objectness: 0.0274 (0.0310)  loss_rpn_box_reg: 0.0179 (0.0245)  time: 0.4305  data: 0.0541  max mem: 5977\n",
      "Epoch: [7]  [120/151]  eta: 0:00:12  lr: 0.000050  loss: 0.1202 (0.1127)  loss_classifier: 0.0271 (0.0270)  loss_box_reg: 0.0298 (0.0294)  loss_objectness: 0.0314 (0.0313)  loss_rpn_box_reg: 0.0244 (0.0251)  time: 0.4260  data: 0.0451  max mem: 5977\n",
      "Epoch: [7]  [130/151]  eta: 0:00:08  lr: 0.000050  loss: 0.1246 (0.1129)  loss_classifier: 0.0271 (0.0272)  loss_box_reg: 0.0297 (0.0296)  loss_objectness: 0.0311 (0.0311)  loss_rpn_box_reg: 0.0265 (0.0251)  time: 0.4260  data: 0.0478  max mem: 5977\n",
      "Epoch: [7]  [140/151]  eta: 0:00:04  lr: 0.000050  loss: 0.1113 (0.1134)  loss_classifier: 0.0256 (0.0276)  loss_box_reg: 0.0290 (0.0300)  loss_objectness: 0.0283 (0.0311)  loss_rpn_box_reg: 0.0198 (0.0247)  time: 0.4179  data: 0.0470  max mem: 5977\n",
      "Epoch: [7]  [150/151]  eta: 0:00:00  lr: 0.000050  loss: 0.1113 (0.1136)  loss_classifier: 0.0251 (0.0273)  loss_box_reg: 0.0283 (0.0298)  loss_objectness: 0.0298 (0.0316)  loss_rpn_box_reg: 0.0202 (0.0249)  time: 0.3916  data: 0.0395  max mem: 5977\n",
      "Epoch: [7] Total time: 0:01:02 (0.4149 s / it)\n",
      "IoU: 0.8494781255722046, mAP: 0.9301332235336304\n",
      "Epoch: [8]  [  0/151]  eta: 0:00:58  lr: 0.000050  loss: 0.0912 (0.0912)  loss_classifier: 0.0316 (0.0316)  loss_box_reg: 0.0228 (0.0228)  loss_objectness: 0.0233 (0.0233)  loss_rpn_box_reg: 0.0136 (0.0136)  time: 0.3893  data: 0.0281  max mem: 5977\n",
      "Epoch: [8]  [ 10/151]  eta: 0:00:55  lr: 0.000050  loss: 0.1244 (0.1192)  loss_classifier: 0.0246 (0.0289)  loss_box_reg: 0.0300 (0.0322)  loss_objectness: 0.0360 (0.0328)  loss_rpn_box_reg: 0.0203 (0.0252)  time: 0.3920  data: 0.0344  max mem: 5977\n",
      "Epoch: [8]  [ 20/151]  eta: 0:00:53  lr: 0.000050  loss: 0.1136 (0.1173)  loss_classifier: 0.0257 (0.0281)  loss_box_reg: 0.0300 (0.0309)  loss_objectness: 0.0310 (0.0329)  loss_rpn_box_reg: 0.0236 (0.0253)  time: 0.4115  data: 0.0447  max mem: 5977\n",
      "Epoch: [8]  [ 30/151]  eta: 0:00:49  lr: 0.000050  loss: 0.1101 (0.1219)  loss_classifier: 0.0266 (0.0274)  loss_box_reg: 0.0275 (0.0302)  loss_objectness: 0.0309 (0.0363)  loss_rpn_box_reg: 0.0243 (0.0280)  time: 0.4227  data: 0.0464  max mem: 5977\n",
      "Epoch: [8]  [ 40/151]  eta: 0:00:45  lr: 0.000050  loss: 0.1061 (0.1190)  loss_classifier: 0.0265 (0.0275)  loss_box_reg: 0.0284 (0.0302)  loss_objectness: 0.0283 (0.0342)  loss_rpn_box_reg: 0.0245 (0.0271)  time: 0.4024  data: 0.0330  max mem: 5977\n",
      "Epoch: [8]  [ 50/151]  eta: 0:00:41  lr: 0.000050  loss: 0.1037 (0.1173)  loss_classifier: 0.0254 (0.0273)  loss_box_reg: 0.0274 (0.0296)  loss_objectness: 0.0240 (0.0338)  loss_rpn_box_reg: 0.0222 (0.0266)  time: 0.4039  data: 0.0385  max mem: 5977\n",
      "Epoch: [8]  [ 60/151]  eta: 0:00:37  lr: 0.000050  loss: 0.1055 (0.1150)  loss_classifier: 0.0232 (0.0269)  loss_box_reg: 0.0254 (0.0296)  loss_objectness: 0.0272 (0.0324)  loss_rpn_box_reg: 0.0198 (0.0260)  time: 0.4265  data: 0.0564  max mem: 5977\n",
      "Epoch: [8]  [ 70/151]  eta: 0:00:33  lr: 0.000050  loss: 0.1039 (0.1135)  loss_classifier: 0.0233 (0.0269)  loss_box_reg: 0.0287 (0.0295)  loss_objectness: 0.0299 (0.0320)  loss_rpn_box_reg: 0.0170 (0.0252)  time: 0.4281  data: 0.0612  max mem: 5977\n",
      "Epoch: [8]  [ 80/151]  eta: 0:00:29  lr: 0.000050  loss: 0.1026 (0.1130)  loss_classifier: 0.0242 (0.0267)  loss_box_reg: 0.0288 (0.0294)  loss_objectness: 0.0295 (0.0317)  loss_rpn_box_reg: 0.0170 (0.0252)  time: 0.4058  data: 0.0450  max mem: 5977\n",
      "Epoch: [8]  [ 90/151]  eta: 0:00:25  lr: 0.000050  loss: 0.1008 (0.1140)  loss_classifier: 0.0251 (0.0268)  loss_box_reg: 0.0297 (0.0296)  loss_objectness: 0.0281 (0.0317)  loss_rpn_box_reg: 0.0216 (0.0258)  time: 0.4105  data: 0.0472  max mem: 5977\n",
      "Epoch: [8]  [100/151]  eta: 0:00:21  lr: 0.000050  loss: 0.1096 (0.1138)  loss_classifier: 0.0251 (0.0267)  loss_box_reg: 0.0297 (0.0295)  loss_objectness: 0.0270 (0.0317)  loss_rpn_box_reg: 0.0223 (0.0258)  time: 0.4302  data: 0.0547  max mem: 5977\n",
      "Epoch: [8]  [110/151]  eta: 0:00:17  lr: 0.000050  loss: 0.1083 (0.1141)  loss_classifier: 0.0257 (0.0271)  loss_box_reg: 0.0279 (0.0300)  loss_objectness: 0.0277 (0.0316)  loss_rpn_box_reg: 0.0198 (0.0254)  time: 0.4238  data: 0.0482  max mem: 5977\n",
      "Epoch: [8]  [120/151]  eta: 0:00:12  lr: 0.000050  loss: 0.1082 (0.1134)  loss_classifier: 0.0253 (0.0271)  loss_box_reg: 0.0278 (0.0299)  loss_objectness: 0.0268 (0.0314)  loss_rpn_box_reg: 0.0197 (0.0249)  time: 0.4205  data: 0.0482  max mem: 5977\n",
      "Epoch: [8]  [130/151]  eta: 0:00:08  lr: 0.000050  loss: 0.0958 (0.1131)  loss_classifier: 0.0241 (0.0269)  loss_box_reg: 0.0261 (0.0296)  loss_objectness: 0.0268 (0.0314)  loss_rpn_box_reg: 0.0197 (0.0251)  time: 0.4079  data: 0.0391  max mem: 5977\n",
      "Epoch: [8]  [140/151]  eta: 0:00:04  lr: 0.000050  loss: 0.0906 (0.1123)  loss_classifier: 0.0240 (0.0267)  loss_box_reg: 0.0262 (0.0294)  loss_objectness: 0.0269 (0.0315)  loss_rpn_box_reg: 0.0152 (0.0247)  time: 0.3991  data: 0.0350  max mem: 5977\n",
      "Epoch: [8]  [150/151]  eta: 0:00:00  lr: 0.000050  loss: 0.0914 (0.1124)  loss_classifier: 0.0242 (0.0267)  loss_box_reg: 0.0265 (0.0293)  loss_objectness: 0.0252 (0.0316)  loss_rpn_box_reg: 0.0179 (0.0248)  time: 0.3936  data: 0.0424  max mem: 5977\n",
      "Epoch: [8] Total time: 0:01:02 (0.4115 s / it)\n",
      "IoU: 0.8495931625366211, mAP: 0.9301332235336304\n",
      "Epoch: [9]  [  0/151]  eta: 0:00:58  lr: 0.000005  loss: 0.0798 (0.0798)  loss_classifier: 0.0256 (0.0256)  loss_box_reg: 0.0287 (0.0287)  loss_objectness: 0.0145 (0.0145)  loss_rpn_box_reg: 0.0110 (0.0110)  time: 0.3883  data: 0.0179  max mem: 5977\n",
      "Epoch: [9]  [ 10/151]  eta: 0:00:57  lr: 0.000005  loss: 0.1001 (0.1121)  loss_classifier: 0.0278 (0.0304)  loss_box_reg: 0.0298 (0.0333)  loss_objectness: 0.0282 (0.0311)  loss_rpn_box_reg: 0.0163 (0.0173)  time: 0.4107  data: 0.0393  max mem: 5977\n",
      "Epoch: [9]  [ 20/151]  eta: 0:00:53  lr: 0.000005  loss: 0.0994 (0.1048)  loss_classifier: 0.0245 (0.0271)  loss_box_reg: 0.0283 (0.0306)  loss_objectness: 0.0271 (0.0273)  loss_rpn_box_reg: 0.0174 (0.0199)  time: 0.4089  data: 0.0440  max mem: 5977\n",
      "Epoch: [9]  [ 30/151]  eta: 0:00:49  lr: 0.000005  loss: 0.0981 (0.1051)  loss_classifier: 0.0228 (0.0271)  loss_box_reg: 0.0273 (0.0304)  loss_objectness: 0.0229 (0.0271)  loss_rpn_box_reg: 0.0201 (0.0205)  time: 0.4121  data: 0.0481  max mem: 5977\n",
      "Epoch: [9]  [ 40/151]  eta: 0:00:46  lr: 0.000005  loss: 0.1011 (0.1066)  loss_classifier: 0.0262 (0.0282)  loss_box_reg: 0.0292 (0.0318)  loss_objectness: 0.0240 (0.0269)  loss_rpn_box_reg: 0.0190 (0.0197)  time: 0.4243  data: 0.0486  max mem: 5977\n",
      "Epoch: [9]  [ 50/151]  eta: 0:00:41  lr: 0.000005  loss: 0.1031 (0.1070)  loss_classifier: 0.0247 (0.0283)  loss_box_reg: 0.0269 (0.0316)  loss_objectness: 0.0240 (0.0273)  loss_rpn_box_reg: 0.0166 (0.0198)  time: 0.4170  data: 0.0449  max mem: 5977\n",
      "Epoch: [9]  [ 60/151]  eta: 0:00:37  lr: 0.000005  loss: 0.1067 (0.1081)  loss_classifier: 0.0275 (0.0290)  loss_box_reg: 0.0269 (0.0316)  loss_objectness: 0.0248 (0.0276)  loss_rpn_box_reg: 0.0164 (0.0199)  time: 0.4056  data: 0.0440  max mem: 5977\n",
      "Epoch: [9]  [ 70/151]  eta: 0:00:33  lr: 0.000005  loss: 0.1110 (0.1127)  loss_classifier: 0.0275 (0.0286)  loss_box_reg: 0.0277 (0.0314)  loss_objectness: 0.0281 (0.0307)  loss_rpn_box_reg: 0.0227 (0.0220)  time: 0.3953  data: 0.0406  max mem: 5977\n",
      "Epoch: [9]  [ 80/151]  eta: 0:00:28  lr: 0.000005  loss: 0.1071 (0.1138)  loss_classifier: 0.0240 (0.0281)  loss_box_reg: 0.0277 (0.0311)  loss_objectness: 0.0281 (0.0316)  loss_rpn_box_reg: 0.0251 (0.0231)  time: 0.3923  data: 0.0420  max mem: 5977\n",
      "Epoch: [9]  [ 90/151]  eta: 0:00:25  lr: 0.000005  loss: 0.0965 (0.1129)  loss_classifier: 0.0249 (0.0279)  loss_box_reg: 0.0288 (0.0309)  loss_objectness: 0.0275 (0.0311)  loss_rpn_box_reg: 0.0196 (0.0230)  time: 0.4146  data: 0.0508  max mem: 5977\n",
      "Epoch: [9]  [100/151]  eta: 0:00:21  lr: 0.000005  loss: 0.1091 (0.1143)  loss_classifier: 0.0250 (0.0280)  loss_box_reg: 0.0289 (0.0312)  loss_objectness: 0.0318 (0.0316)  loss_rpn_box_reg: 0.0207 (0.0235)  time: 0.4297  data: 0.0556  max mem: 5977\n",
      "Epoch: [9]  [110/151]  eta: 0:00:16  lr: 0.000005  loss: 0.1217 (0.1154)  loss_classifier: 0.0257 (0.0278)  loss_box_reg: 0.0290 (0.0309)  loss_objectness: 0.0362 (0.0324)  loss_rpn_box_reg: 0.0269 (0.0243)  time: 0.4083  data: 0.0440  max mem: 5977\n",
      "Epoch: [9]  [120/151]  eta: 0:00:12  lr: 0.000005  loss: 0.0979 (0.1152)  loss_classifier: 0.0262 (0.0277)  loss_box_reg: 0.0290 (0.0307)  loss_objectness: 0.0329 (0.0324)  loss_rpn_box_reg: 0.0217 (0.0243)  time: 0.3995  data: 0.0422  max mem: 5977\n",
      "Epoch: [9]  [130/151]  eta: 0:00:08  lr: 0.000005  loss: 0.1033 (0.1153)  loss_classifier: 0.0247 (0.0276)  loss_box_reg: 0.0278 (0.0305)  loss_objectness: 0.0275 (0.0326)  loss_rpn_box_reg: 0.0214 (0.0246)  time: 0.4189  data: 0.0505  max mem: 5977\n",
      "Epoch: [9]  [140/151]  eta: 0:00:04  lr: 0.000005  loss: 0.1052 (0.1144)  loss_classifier: 0.0253 (0.0275)  loss_box_reg: 0.0277 (0.0303)  loss_objectness: 0.0300 (0.0322)  loss_rpn_box_reg: 0.0228 (0.0244)  time: 0.4156  data: 0.0464  max mem: 5977\n",
      "Epoch: [9]  [150/151]  eta: 0:00:00  lr: 0.000005  loss: 0.1058 (0.1146)  loss_classifier: 0.0254 (0.0276)  loss_box_reg: 0.0287 (0.0303)  loss_objectness: 0.0288 (0.0323)  loss_rpn_box_reg: 0.0217 (0.0244)  time: 0.3900  data: 0.0391  max mem: 5977\n",
      "Epoch: [9] Total time: 0:01:01 (0.4083 s / it)\n",
      "IoU: 0.8499450087547302, mAP: 0.9301332235336304\n",
      "Epoch: [10]  [  0/151]  eta: 0:01:16  lr: 0.000005  loss: 0.1267 (0.1267)  loss_classifier: 0.0411 (0.0411)  loss_box_reg: 0.0512 (0.0512)  loss_objectness: 0.0196 (0.0196)  loss_rpn_box_reg: 0.0148 (0.0148)  time: 0.5089  data: 0.1157  max mem: 5977\n",
      "Epoch: [10]  [ 10/151]  eta: 0:00:58  lr: 0.000005  loss: 0.1179 (0.1269)  loss_classifier: 0.0254 (0.0308)  loss_box_reg: 0.0297 (0.0335)  loss_objectness: 0.0308 (0.0364)  loss_rpn_box_reg: 0.0199 (0.0262)  time: 0.4125  data: 0.0523  max mem: 5977\n",
      "Epoch: [10]  [ 20/151]  eta: 0:00:52  lr: 0.000005  loss: 0.1082 (0.1243)  loss_classifier: 0.0252 (0.0289)  loss_box_reg: 0.0288 (0.0313)  loss_objectness: 0.0308 (0.0371)  loss_rpn_box_reg: 0.0195 (0.0269)  time: 0.3978  data: 0.0430  max mem: 5977\n",
      "Epoch: [10]  [ 30/151]  eta: 0:00:48  lr: 0.000005  loss: 0.1042 (0.1216)  loss_classifier: 0.0244 (0.0285)  loss_box_reg: 0.0285 (0.0309)  loss_objectness: 0.0290 (0.0354)  loss_rpn_box_reg: 0.0195 (0.0269)  time: 0.3899  data: 0.0344  max mem: 5977\n",
      "Epoch: [10]  [ 40/151]  eta: 0:00:44  lr: 0.000005  loss: 0.1193 (0.1220)  loss_classifier: 0.0249 (0.0281)  loss_box_reg: 0.0285 (0.0309)  loss_objectness: 0.0303 (0.0353)  loss_rpn_box_reg: 0.0228 (0.0277)  time: 0.3998  data: 0.0413  max mem: 5977\n",
      "Epoch: [10]  [ 50/151]  eta: 0:00:40  lr: 0.000005  loss: 0.1156 (0.1184)  loss_classifier: 0.0255 (0.0277)  loss_box_reg: 0.0294 (0.0307)  loss_objectness: 0.0293 (0.0332)  loss_rpn_box_reg: 0.0250 (0.0268)  time: 0.4024  data: 0.0458  max mem: 5977\n",
      "Epoch: [10]  [ 60/151]  eta: 0:00:36  lr: 0.000005  loss: 0.1094 (0.1185)  loss_classifier: 0.0259 (0.0274)  loss_box_reg: 0.0275 (0.0302)  loss_objectness: 0.0307 (0.0347)  loss_rpn_box_reg: 0.0222 (0.0263)  time: 0.4061  data: 0.0449  max mem: 5977\n",
      "Epoch: [10]  [ 70/151]  eta: 0:00:32  lr: 0.000005  loss: 0.1077 (0.1163)  loss_classifier: 0.0262 (0.0273)  loss_box_reg: 0.0261 (0.0302)  loss_objectness: 0.0306 (0.0334)  loss_rpn_box_reg: 0.0192 (0.0255)  time: 0.4110  data: 0.0474  max mem: 5977\n",
      "Epoch: [10]  [ 80/151]  eta: 0:00:28  lr: 0.000005  loss: 0.1005 (0.1149)  loss_classifier: 0.0262 (0.0274)  loss_box_reg: 0.0266 (0.0303)  loss_objectness: 0.0233 (0.0325)  loss_rpn_box_reg: 0.0174 (0.0248)  time: 0.4013  data: 0.0373  max mem: 5977\n",
      "Epoch: [10]  [ 90/151]  eta: 0:00:24  lr: 0.000005  loss: 0.1034 (0.1140)  loss_classifier: 0.0254 (0.0274)  loss_box_reg: 0.0295 (0.0303)  loss_objectness: 0.0270 (0.0320)  loss_rpn_box_reg: 0.0174 (0.0244)  time: 0.4124  data: 0.0436  max mem: 5977\n",
      "Epoch: [10]  [100/151]  eta: 0:00:20  lr: 0.000005  loss: 0.1028 (0.1126)  loss_classifier: 0.0240 (0.0272)  loss_box_reg: 0.0265 (0.0299)  loss_objectness: 0.0329 (0.0317)  loss_rpn_box_reg: 0.0172 (0.0238)  time: 0.4072  data: 0.0414  max mem: 5977\n",
      "Epoch: [10]  [110/151]  eta: 0:00:16  lr: 0.000005  loss: 0.0968 (0.1125)  loss_classifier: 0.0254 (0.0272)  loss_box_reg: 0.0266 (0.0299)  loss_objectness: 0.0230 (0.0318)  loss_rpn_box_reg: 0.0167 (0.0236)  time: 0.4196  data: 0.0424  max mem: 5977\n",
      "Epoch: [10]  [120/151]  eta: 0:00:12  lr: 0.000005  loss: 0.1061 (0.1132)  loss_classifier: 0.0254 (0.0273)  loss_box_reg: 0.0286 (0.0300)  loss_objectness: 0.0281 (0.0319)  loss_rpn_box_reg: 0.0221 (0.0240)  time: 0.4393  data: 0.0578  max mem: 5977\n",
      "Epoch: [10]  [130/151]  eta: 0:00:08  lr: 0.000005  loss: 0.1087 (0.1142)  loss_classifier: 0.0251 (0.0272)  loss_box_reg: 0.0272 (0.0300)  loss_objectness: 0.0284 (0.0324)  loss_rpn_box_reg: 0.0271 (0.0246)  time: 0.4267  data: 0.0495  max mem: 5977\n",
      "Epoch: [10]  [140/151]  eta: 0:00:04  lr: 0.000005  loss: 0.1087 (0.1142)  loss_classifier: 0.0259 (0.0273)  loss_box_reg: 0.0287 (0.0300)  loss_objectness: 0.0254 (0.0322)  loss_rpn_box_reg: 0.0233 (0.0246)  time: 0.4196  data: 0.0452  max mem: 5977\n",
      "Epoch: [10]  [150/151]  eta: 0:00:00  lr: 0.000005  loss: 0.0973 (0.1142)  loss_classifier: 0.0263 (0.0272)  loss_box_reg: 0.0284 (0.0299)  loss_objectness: 0.0254 (0.0324)  loss_rpn_box_reg: 0.0199 (0.0246)  time: 0.4050  data: 0.0469  max mem: 5977\n",
      "Epoch: [10] Total time: 0:01:01 (0.4099 s / it)\n",
      "IoU: 0.8562491536140442, mAP: 0.9301332235336304\n",
      "Epoch: [11]  [  0/151]  eta: 0:01:01  lr: 0.000005  loss: 0.0828 (0.0828)  loss_classifier: 0.0249 (0.0249)  loss_box_reg: 0.0275 (0.0275)  loss_objectness: 0.0201 (0.0201)  loss_rpn_box_reg: 0.0104 (0.0104)  time: 0.4084  data: 0.0280  max mem: 5977\n",
      "Epoch: [11]  [ 10/151]  eta: 0:00:57  lr: 0.000005  loss: 0.1021 (0.0991)  loss_classifier: 0.0239 (0.0250)  loss_box_reg: 0.0272 (0.0280)  loss_objectness: 0.0233 (0.0262)  loss_rpn_box_reg: 0.0157 (0.0199)  time: 0.4091  data: 0.0458  max mem: 5977\n",
      "Epoch: [11]  [ 20/151]  eta: 0:00:54  lr: 0.000005  loss: 0.0995 (0.1028)  loss_classifier: 0.0210 (0.0245)  loss_box_reg: 0.0263 (0.0276)  loss_objectness: 0.0270 (0.0281)  loss_rpn_box_reg: 0.0178 (0.0226)  time: 0.4171  data: 0.0502  max mem: 5977\n",
      "Epoch: [11]  [ 30/151]  eta: 0:00:50  lr: 0.000005  loss: 0.1016 (0.1111)  loss_classifier: 0.0283 (0.0270)  loss_box_reg: 0.0293 (0.0301)  loss_objectness: 0.0292 (0.0314)  loss_rpn_box_reg: 0.0187 (0.0226)  time: 0.4258  data: 0.0559  max mem: 5977\n",
      "Epoch: [11]  [ 40/151]  eta: 0:00:46  lr: 0.000005  loss: 0.1039 (0.1109)  loss_classifier: 0.0293 (0.0271)  loss_box_reg: 0.0294 (0.0297)  loss_objectness: 0.0291 (0.0315)  loss_rpn_box_reg: 0.0216 (0.0226)  time: 0.4187  data: 0.0475  max mem: 5977\n",
      "Epoch: [11]  [ 50/151]  eta: 0:00:42  lr: 0.000005  loss: 0.1012 (0.1082)  loss_classifier: 0.0249 (0.0274)  loss_box_reg: 0.0287 (0.0295)  loss_objectness: 0.0261 (0.0304)  loss_rpn_box_reg: 0.0181 (0.0210)  time: 0.4152  data: 0.0362  max mem: 5977\n",
      "Epoch: [11]  [ 60/151]  eta: 0:00:38  lr: 0.000005  loss: 0.1025 (0.1109)  loss_classifier: 0.0240 (0.0276)  loss_box_reg: 0.0294 (0.0300)  loss_objectness: 0.0277 (0.0305)  loss_rpn_box_reg: 0.0184 (0.0228)  time: 0.4248  data: 0.0525  max mem: 5977\n",
      "Epoch: [11]  [ 70/151]  eta: 0:00:33  lr: 0.000005  loss: 0.1188 (0.1126)  loss_classifier: 0.0240 (0.0275)  loss_box_reg: 0.0299 (0.0301)  loss_objectness: 0.0304 (0.0314)  loss_rpn_box_reg: 0.0285 (0.0236)  time: 0.4129  data: 0.0557  max mem: 5977\n",
      "Epoch: [11]  [ 80/151]  eta: 0:00:29  lr: 0.000005  loss: 0.1188 (0.1132)  loss_classifier: 0.0246 (0.0276)  loss_box_reg: 0.0326 (0.0302)  loss_objectness: 0.0323 (0.0315)  loss_rpn_box_reg: 0.0249 (0.0240)  time: 0.4024  data: 0.0437  max mem: 5977\n",
      "Epoch: [11]  [ 90/151]  eta: 0:00:25  lr: 0.000005  loss: 0.1077 (0.1116)  loss_classifier: 0.0240 (0.0274)  loss_box_reg: 0.0265 (0.0297)  loss_objectness: 0.0272 (0.0308)  loss_rpn_box_reg: 0.0228 (0.0237)  time: 0.4032  data: 0.0394  max mem: 5977\n",
      "Epoch: [11]  [100/151]  eta: 0:00:20  lr: 0.000005  loss: 0.0974 (0.1114)  loss_classifier: 0.0235 (0.0269)  loss_box_reg: 0.0251 (0.0293)  loss_objectness: 0.0242 (0.0311)  loss_rpn_box_reg: 0.0246 (0.0242)  time: 0.3940  data: 0.0328  max mem: 5977\n",
      "Epoch: [11]  [110/151]  eta: 0:00:16  lr: 0.000005  loss: 0.1006 (0.1125)  loss_classifier: 0.0251 (0.0271)  loss_box_reg: 0.0277 (0.0294)  loss_objectness: 0.0279 (0.0316)  loss_rpn_box_reg: 0.0259 (0.0244)  time: 0.3937  data: 0.0315  max mem: 5977\n",
      "Epoch: [11]  [120/151]  eta: 0:00:12  lr: 0.000005  loss: 0.1042 (0.1120)  loss_classifier: 0.0271 (0.0271)  loss_box_reg: 0.0295 (0.0294)  loss_objectness: 0.0261 (0.0312)  loss_rpn_box_reg: 0.0222 (0.0243)  time: 0.3960  data: 0.0341  max mem: 5977\n",
      "Epoch: [11]  [130/151]  eta: 0:00:08  lr: 0.000005  loss: 0.1042 (0.1124)  loss_classifier: 0.0246 (0.0270)  loss_box_reg: 0.0315 (0.0296)  loss_objectness: 0.0266 (0.0313)  loss_rpn_box_reg: 0.0247 (0.0246)  time: 0.3984  data: 0.0406  max mem: 5977\n",
      "Epoch: [11]  [140/151]  eta: 0:00:04  lr: 0.000005  loss: 0.1002 (0.1124)  loss_classifier: 0.0242 (0.0271)  loss_box_reg: 0.0318 (0.0298)  loss_objectness: 0.0266 (0.0310)  loss_rpn_box_reg: 0.0230 (0.0245)  time: 0.4116  data: 0.0504  max mem: 5977\n",
      "Epoch: [11]  [150/151]  eta: 0:00:00  lr: 0.000005  loss: 0.0990 (0.1142)  loss_classifier: 0.0279 (0.0273)  loss_box_reg: 0.0304 (0.0301)  loss_objectness: 0.0252 (0.0319)  loss_rpn_box_reg: 0.0220 (0.0249)  time: 0.4118  data: 0.0565  max mem: 5977\n",
      "Epoch: [11] Total time: 0:01:01 (0.4088 s / it)\n",
      "IoU: 0.850444495677948, mAP: 0.9301332235336304\n",
      "Epoch: [12]  [  0/151]  eta: 0:00:58  lr: 0.000001  loss: 0.1383 (0.1383)  loss_classifier: 0.0400 (0.0400)  loss_box_reg: 0.0409 (0.0409)  loss_objectness: 0.0389 (0.0389)  loss_rpn_box_reg: 0.0185 (0.0185)  time: 0.3867  data: 0.0349  max mem: 5977\n",
      "Epoch: [12]  [ 10/151]  eta: 0:00:56  lr: 0.000001  loss: 0.1215 (0.1222)  loss_classifier: 0.0299 (0.0331)  loss_box_reg: 0.0307 (0.0344)  loss_objectness: 0.0337 (0.0343)  loss_rpn_box_reg: 0.0178 (0.0204)  time: 0.3989  data: 0.0357  max mem: 5977\n",
      "Epoch: [12]  [ 20/151]  eta: 0:00:54  lr: 0.000001  loss: 0.1215 (0.1203)  loss_classifier: 0.0279 (0.0315)  loss_box_reg: 0.0294 (0.0325)  loss_objectness: 0.0309 (0.0328)  loss_rpn_box_reg: 0.0219 (0.0236)  time: 0.4141  data: 0.0477  max mem: 5977\n",
      "Epoch: [12]  [ 30/151]  eta: 0:00:50  lr: 0.000001  loss: 0.1167 (0.1192)  loss_classifier: 0.0252 (0.0297)  loss_box_reg: 0.0254 (0.0301)  loss_objectness: 0.0313 (0.0335)  loss_rpn_box_reg: 0.0262 (0.0258)  time: 0.4290  data: 0.0578  max mem: 5977\n",
      "Epoch: [12]  [ 40/151]  eta: 0:00:45  lr: 0.000001  loss: 0.1070 (0.1146)  loss_classifier: 0.0241 (0.0285)  loss_box_reg: 0.0263 (0.0295)  loss_objectness: 0.0289 (0.0314)  loss_rpn_box_reg: 0.0243 (0.0253)  time: 0.4104  data: 0.0466  max mem: 5977\n",
      "Epoch: [12]  [ 50/151]  eta: 0:00:41  lr: 0.000001  loss: 0.0970 (0.1119)  loss_classifier: 0.0242 (0.0281)  loss_box_reg: 0.0269 (0.0297)  loss_objectness: 0.0219 (0.0305)  loss_rpn_box_reg: 0.0158 (0.0236)  time: 0.3906  data: 0.0373  max mem: 5977\n",
      "Epoch: [12]  [ 60/151]  eta: 0:00:37  lr: 0.000001  loss: 0.0931 (0.1109)  loss_classifier: 0.0259 (0.0281)  loss_box_reg: 0.0269 (0.0294)  loss_objectness: 0.0293 (0.0309)  loss_rpn_box_reg: 0.0145 (0.0225)  time: 0.3982  data: 0.0338  max mem: 5977\n",
      "Epoch: [12]  [ 70/151]  eta: 0:00:32  lr: 0.000001  loss: 0.1007 (0.1116)  loss_classifier: 0.0247 (0.0278)  loss_box_reg: 0.0269 (0.0294)  loss_objectness: 0.0282 (0.0309)  loss_rpn_box_reg: 0.0164 (0.0235)  time: 0.4063  data: 0.0353  max mem: 5977\n",
      "Epoch: [12]  [ 80/151]  eta: 0:00:32  lr: 0.000001  loss: 0.1144 (0.1143)  loss_classifier: 0.0247 (0.0279)  loss_box_reg: 0.0274 (0.0295)  loss_objectness: 0.0282 (0.0326)  loss_rpn_box_reg: 0.0227 (0.0243)  time: 0.5930  data: 0.0671  max mem: 5977\n",
      "Epoch: [12]  [ 90/151]  eta: 0:00:29  lr: 0.000001  loss: 0.1037 (0.1136)  loss_classifier: 0.0272 (0.0278)  loss_box_reg: 0.0268 (0.0295)  loss_objectness: 0.0308 (0.0320)  loss_rpn_box_reg: 0.0239 (0.0243)  time: 0.7700  data: 0.0845  max mem: 5977\n",
      "Epoch: [12]  [100/151]  eta: 0:00:26  lr: 0.000001  loss: 0.1116 (0.1139)  loss_classifier: 0.0265 (0.0277)  loss_box_reg: 0.0275 (0.0295)  loss_objectness: 0.0308 (0.0320)  loss_rpn_box_reg: 0.0245 (0.0246)  time: 0.8294  data: 0.0884  max mem: 5977\n",
      "Epoch: [12]  [110/151]  eta: 0:00:22  lr: 0.000001  loss: 0.1121 (0.1139)  loss_classifier: 0.0252 (0.0275)  loss_box_reg: 0.0278 (0.0295)  loss_objectness: 0.0320 (0.0320)  loss_rpn_box_reg: 0.0279 (0.0249)  time: 0.8490  data: 0.0846  max mem: 5977\n",
      "Epoch: [12]  [120/151]  eta: 0:00:17  lr: 0.000001  loss: 0.1061 (0.1124)  loss_classifier: 0.0242 (0.0272)  loss_box_reg: 0.0270 (0.0292)  loss_objectness: 0.0277 (0.0314)  loss_rpn_box_reg: 0.0249 (0.0246)  time: 0.7634  data: 0.0725  max mem: 5977\n",
      "Epoch: [12]  [130/151]  eta: 0:00:12  lr: 0.000001  loss: 0.1073 (0.1128)  loss_classifier: 0.0259 (0.0272)  loss_box_reg: 0.0273 (0.0292)  loss_objectness: 0.0281 (0.0316)  loss_rpn_box_reg: 0.0217 (0.0249)  time: 0.7693  data: 0.0993  max mem: 5977\n",
      "Epoch: [12]  [140/151]  eta: 0:00:06  lr: 0.000001  loss: 0.1079 (0.1131)  loss_classifier: 0.0273 (0.0273)  loss_box_reg: 0.0294 (0.0293)  loss_objectness: 0.0281 (0.0318)  loss_rpn_box_reg: 0.0202 (0.0248)  time: 0.7999  data: 0.1184  max mem: 5977\n",
      "Epoch: [12]  [150/151]  eta: 0:00:00  lr: 0.000001  loss: 0.1033 (0.1129)  loss_classifier: 0.0272 (0.0272)  loss_box_reg: 0.0281 (0.0291)  loss_objectness: 0.0311 (0.0320)  loss_rpn_box_reg: 0.0174 (0.0245)  time: 0.7709  data: 0.0992  max mem: 5977\n",
      "Epoch: [12] Total time: 0:01:32 (0.6101 s / it)\n",
      "IoU: 0.8490697741508484, mAP: 0.9301332235336304\n",
      "Epoch: [13]  [  0/151]  eta: 0:01:33  lr: 0.000001  loss: 0.0909 (0.0909)  loss_classifier: 0.0192 (0.0192)  loss_box_reg: 0.0242 (0.0242)  loss_objectness: 0.0256 (0.0256)  loss_rpn_box_reg: 0.0218 (0.0218)  time: 0.6173  data: 0.0722  max mem: 5977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m max_IoU \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# train for one epoch, printing every 10 iterations\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# update the learning rate\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\engine.py:57\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m         lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 57\u001b[0m     metric_logger\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m=\u001b[39mlosses_reduced, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_dict_reduced)\n\u001b[0;32m     58\u001b[0m     metric_logger\u001b[38;5;241m.\u001b[39mupdate(lr\u001b[38;5;241m=\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metric_logger\n",
      "File \u001b[1;32md:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\utils.py:121\u001b[0m, in \u001b[0;36mMetricLogger.update\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 121\u001b[0m         v \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m))\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeters[k]\u001b[38;5;241m.\u001b[39mupdate(v)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# let's train it just for 2 epochs\n",
    "num_epochs = 20\n",
    "max_IoU = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    IoU, mAP = validate(model, val_loader, device=device)\n",
    "    print(f\"IoU: {IoU}, mAP: {mAP}\", )\n",
    "\n",
    "    if IoU > max_IoU:\n",
    "        max_IoU = IoU\n",
    "        model_name = f\"FasterRCNN_MobileNetV3_small_{max_IoU:.3f}.pth\"\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    # evaluate(model, val_loader, device=device)\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Axioo Pongo\\AppData\\Local\\Temp\\ipykernel_3524\\3736781072.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_model.load_state_dict(torch.load('FasterRCNN_MobileNetV3_small_0.86.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "0.7093819\n",
      "[0.29928216 0.15594748 0.13304232 0.12764111 0.07659749]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw \n",
    "\n",
    "# predict one image\n",
    "image, target = test_loader.dataset[0]\n",
    "test_model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=2,\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ").to(device)\n",
    "test_model.load_state_dict(torch.load('FasterRCNN_MobileNetV3_small_0.86.pth'))\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = test_model([image.to(device)])[0]\n",
    "\n",
    "    mAP = get_mAP(\n",
    "        prediction[\"boxes\"].cpu(), \n",
    "        prediction[\"labels\"].cpu(), \n",
    "        prediction[\"scores\"].cpu(),\n",
    "          target[\"boxes\"], \n",
    "          target[\"labels\"]\n",
    "          )\n",
    "    print(mAP)\n",
    "    # get the predicted bounding boxes\n",
    "    pred_boxes = prediction[\"boxes\"].cpu().numpy()\n",
    "    # get the predicted labels\n",
    "    pred_labels = prediction[\"labels\"].cpu().numpy()\n",
    "    # get the predicted scores\n",
    "    pred_scores = prediction[\"scores\"].cpu().numpy()\n",
    "    # get the ground truth bounding boxes\n",
    "    gt_boxes = target[\"boxes\"].numpy()\n",
    "    # get the ground truth labels\n",
    "    gt_labels = target[\"labels\"].numpy()\n",
    "    # get the ground truth areas\n",
    "    gt_areas = target[\"area\"].numpy()\n",
    "    # get the ground truth iscrowd\n",
    "    gt_iscrowd = target[\"iscrowd\"].numpy()\n",
    "    # get the ground truth image_id\n",
    "    gt_image_id = target[\"image_id\"].numpy()\n",
    "    # get the IoU\n",
    "    iou = getIoU(pred_boxes[0], gt_boxes[0])\n",
    "    img = Image.fromarray(image.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "    #show bbox\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle([(pred_boxes[0][0], pred_boxes[0][1]), (pred_boxes[0][2], pred_boxes[0][3])], outline =\"red\", width=3)\n",
    "    draw.rectangle([(gt_boxes[0][0], gt_boxes[0][1]), (gt_boxes[0][2], gt_boxes[0][3])], outline =\"green\", width=3)\n",
    "    img.show()\n",
    "\n",
    "    print(iou)\n",
    "    print(pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8106864 tensor(0.8118)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "IoU, mAP = validate(test_model, test_loader, device=device)\n",
    "\n",
    "print(IoU, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Results do not correspond to current coco set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\engine.py:101\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m     99\u001b[0m res \u001b[38;5;241m=\u001b[39m {target[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]: output \u001b[38;5;28;01mfor\u001b[39;00m target, output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(targets, outputs)}\n\u001b[0;32m    100\u001b[0m evaluator_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 101\u001b[0m \u001b[43mcoco_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m evaluator_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m evaluator_time\n\u001b[0;32m    103\u001b[0m metric_logger\u001b[38;5;241m.\u001b[39mupdate(model_time\u001b[38;5;241m=\u001b[39mmodel_time, evaluator_time\u001b[38;5;241m=\u001b[39mevaluator_time)\n",
      "File \u001b[1;32md:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\coco_eval.py:35\u001b[0m, in \u001b[0;36mCocoEvaluator.update\u001b[1;34m(self, predictions)\u001b[0m\n\u001b[0;32m     33\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare(predictions, iou_type)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m redirect_stdout(io\u001b[38;5;241m.\u001b[39mStringIO()):\n\u001b[1;32m---> 35\u001b[0m     coco_dt \u001b[38;5;241m=\u001b[39m \u001b[43mCOCO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadRes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoco_gt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;28;01melse\u001b[39;00m COCO()\n\u001b[0;32m     36\u001b[0m coco_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoco_eval[iou_type]\n\u001b[0;32m     38\u001b[0m coco_eval\u001b[38;5;241m.\u001b[39mcocoDt \u001b[38;5;241m=\u001b[39m coco_dt\n",
      "File \u001b[1;32md:\\Tugazz\\Coolyeah\\VISKOM\\TUBES\\.venv\\lib\\site-packages\\pycocotools\\coco.py:327\u001b[0m, in \u001b[0;36mCOCO.loadRes\u001b[1;34m(self, resFile)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(anns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults in not an array of objects\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    326\u001b[0m annsImgIds \u001b[38;5;241m=\u001b[39m [ann[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m anns]\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(annsImgIds) \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mset\u001b[39m(annsImgIds) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetImgIds())), \\\n\u001b[0;32m    328\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults do not correspond to current coco set\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m anns[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    330\u001b[0m     imgIds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([img[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m]]) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m([ann[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m anns])\n",
      "\u001b[1;31mAssertionError\u001b[0m: Results do not correspond to current coco set"
     ]
    }
   ],
   "source": [
    "from engine import evaluate\n",
    "# evaluate(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import v2 as T\n",
    "\n",
    "# def get_transform(train):\n",
    "#     transforms = []\n",
    "#     if train:\n",
    "#         transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "#     transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "#     transforms.append(T.ToPureTensor())\n",
    "#     return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# criterion = torch.nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import sys\n",
    "# import time\n",
    "\n",
    "# import torch\n",
    "# import torchvision.models.detection.mask_rcnn\n",
    "# import utils\n",
    "# from coco_eval import CocoEvaluator\n",
    "# from coco_utils import get_coco_api_from_dataset\n",
    "\n",
    "\n",
    "# def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, scaler=None):\n",
    "#     model.train()\n",
    "#     metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "#     metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "#     header = f\"Epoch: [{epoch}]\"\n",
    "\n",
    "#     lr_scheduler = None\n",
    "#     if epoch == 0:\n",
    "#         warmup_factor = 1.0 / 1000\n",
    "#         warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "#             optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "#         )\n",
    "\n",
    "#     for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "#         images = list(image.to(device) for image in images)\n",
    "#         targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
    "#         with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "#             loss_dict = model(images, targets)\n",
    "#             losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "#         # reduce losses over all GPUs for logging purposes\n",
    "#         loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "#         losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "#         loss_value = losses_reduced.item()\n",
    "\n",
    "#         if not math.isfinite(loss_value):\n",
    "#             print(f\"Loss is {loss_value}, stopping training\")\n",
    "#             print(loss_dict_reduced)\n",
    "#             sys.exit(1)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         if scaler is not None:\n",
    "#             scaler.scale(losses).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "#         else:\n",
    "#             losses.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         if lr_scheduler is not None:\n",
    "#             lr_scheduler.step()\n",
    "\n",
    "#         metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "#         metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "#     return metric_logger\n",
    "\n",
    "\n",
    "# def _get_iou_types(model):\n",
    "#     model_without_ddp = model\n",
    "#     if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "#         model_without_ddp = model.module\n",
    "#     iou_types = [\"bbox\"]\n",
    "#     if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
    "#         iou_types.append(\"segm\")\n",
    "#     if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
    "#         iou_types.append(\"keypoints\")\n",
    "#     return iou_types\n",
    "\n",
    "\n",
    "# @torch.inference_mode()\n",
    "# def evaluate(model, data_loader, device):\n",
    "#     n_threads = torch.get_num_threads()\n",
    "#     # FIXME remove this and make paste_masks_in_image run on the GPU\n",
    "#     torch.set_num_threads(1)\n",
    "#     cpu_device = torch.device(\"cpu\")\n",
    "#     model.eval()\n",
    "#     metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "#     header = \"Test:\"\n",
    "\n",
    "#     coco = get_coco_api_from_dataset(data_loader.dataset)\n",
    "#     iou_types = _get_iou_types(model)\n",
    "#     coco_evaluator = CocoEvaluator(coco, iou_types)\n",
    "\n",
    "#     for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
    "#         images = list(img.to(device) for img in images)\n",
    "\n",
    "#         if torch.cuda.is_available():\n",
    "#             torch.cuda.synchronize()\n",
    "#         model_time = time.time()\n",
    "#         outputs = model(images)\n",
    "\n",
    "#         outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "#         model_time = time.time() - model_time\n",
    "\n",
    "#         res = {target[\"image_id\"]: output for target, output in zip(targets, outputs)}\n",
    "#         evaluator_time = time.time()\n",
    "#         coco_evaluator.update(res)\n",
    "#         evaluator_time = time.time() - evaluator_time\n",
    "#         metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
    "\n",
    "#     # gather the stats from all processes\n",
    "#     metric_logger.synchronize_between_processes()\n",
    "#     print(\"Averaged stats:\", metric_logger)\n",
    "#     coco_evaluator.synchronize_between_processes()\n",
    "\n",
    "#     # accumulate predictions from all images\n",
    "#     coco_evaluator.accumulate()\n",
    "#     coco_evaluator.summarize()\n",
    "#     torch.set_num_threads(n_threads)\n",
    "#     return coco_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# num_epochs = 10\n",
    "# max_mAP = 0\n",
    "# model_name = ''\n",
    "# date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_one_epoch(model, criterion, optimizer, train_loader, epoch)\n",
    "#     mAP = evaluate(model, val_loader)\n",
    "#     scheduler.step()  # Update learning rate\n",
    "\n",
    "#     if mAP > max_mAP:\n",
    "#         max_mAP = mAP\n",
    "#         model_name = f\"last_MobileNetSSD{date}_{mAP:.3f}.pt\"\n",
    "#         torch.save(model.state_dict(), model_name)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
